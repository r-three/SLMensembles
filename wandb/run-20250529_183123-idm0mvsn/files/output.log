Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.

==================================================
Starting Round 0 at: 2025-05-29 18:31:30
==================================================
Round '0' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-29/run_6/round_0
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
[34m[1mwandb[0m: [33mWARNING[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [10:37<00:00, 56.66s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [11:17<00:00, 67.77s/it]
{'eval_loss': 1.4590474367141724, 'eval_runtime': 51.2767, 'eval_samples_per_second': 37.951, 'eval_steps_per_second': 4.758, 'epoch': 0}
{'loss': 3.6455, 'grad_norm': 172.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'eval_loss': 1.4590474367141724, 'eval_runtime': 51.5508, 'eval_samples_per_second': 37.749, 'eval_steps_per_second': 4.733, 'epoch': 0.0}
{'loss': 3.6162, 'grad_norm': 184.0, 'learning_rate': 2e-08, 'epoch': 0.0}
{'eval_loss': 1.4576035737991333, 'eval_runtime': 51.796, 'eval_samples_per_second': 37.57, 'eval_steps_per_second': 4.711, 'epoch': 0.0}
{'loss': 3.8498, 'grad_norm': 182.0, 'learning_rate': 4e-08, 'epoch': 0.0}
{'eval_loss': 1.45887291431427, 'eval_runtime': 51.7755, 'eval_samples_per_second': 37.585, 'eval_steps_per_second': 4.713, 'epoch': 0.0}
{'loss': 3.263, 'grad_norm': 166.0, 'learning_rate': 6e-08, 'epoch': 0.0}
{'eval_loss': 1.4571455717086792, 'eval_runtime': 51.7228, 'eval_samples_per_second': 37.624, 'eval_steps_per_second': 4.717, 'epoch': 0.0}
{'loss': 3.728, 'grad_norm': 181.0, 'learning_rate': 8e-08, 'epoch': 0.0}
{'eval_loss': 1.4583638906478882, 'eval_runtime': 51.6954, 'eval_samples_per_second': 37.644, 'eval_steps_per_second': 4.72, 'epoch': 0.0}
{'loss': 3.2927, 'grad_norm': 176.0, 'learning_rate': 1e-07, 'epoch': 0.0}
{'eval_loss': 1.4583725929260254, 'eval_runtime': 51.6891, 'eval_samples_per_second': 37.648, 'eval_steps_per_second': 4.721, 'epoch': 0.0}
{'loss': 3.6465, 'grad_norm': 195.0, 'learning_rate': 1.2e-07, 'epoch': 0.0}
{'eval_loss': 1.45911705493927, 'eval_runtime': 51.7, 'eval_samples_per_second': 37.64, 'eval_steps_per_second': 4.72, 'epoch': 0.0}
{'loss': 3.578, 'grad_norm': 178.0, 'learning_rate': 1.4e-07, 'epoch': 0.0}
{'eval_loss': 1.4595913887023926, 'eval_runtime': 51.7492, 'eval_samples_per_second': 37.604, 'eval_steps_per_second': 4.715, 'epoch': 0.0}
{'loss': 3.0021, 'grad_norm': 145.0, 'learning_rate': 1.6e-07, 'epoch': 0.0}
{'eval_loss': 1.4583485126495361, 'eval_runtime': 51.7019, 'eval_samples_per_second': 37.639, 'eval_steps_per_second': 4.719, 'epoch': 0.0}
{'loss': 3.3741, 'grad_norm': 160.0, 'learning_rate': 1.8e-07, 'epoch': 0.0}
{'eval_loss': 1.457826018333435, 'eval_runtime': 51.752, 'eval_samples_per_second': 37.602, 'eval_steps_per_second': 4.715, 'epoch': 0.0}
{'train_runtime': 637.6401, 'train_samples_per_second': 0.502, 'train_steps_per_second': 0.016, 'train_loss': 3.499584412574768, 'epoch': 0.0}

-------------------------
Student evaluation for 0: 1.38359534740448
Ensemble evaluation for 0: 1.38359534740448
Teacher evaluation for 0: 1.0332053899765015
-------------------------
==================================================
Ending Round 0 at: 2025-05-29 18:42:59
Completed in: 11m 28s
Total training time: 11m 36s
==================================================


==================================================
Starting Round 1 at: 2025-05-29 18:42:59
==================================================
Round '1' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-29/run_6/round_1
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 0 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [20:09<00:00, 108.62s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [20:55<00:00, 125.54s/it]               
{'eval_loss': 1.458141565322876, 'eval_runtime': 102.8126, 'eval_samples_per_second': 18.928, 'eval_steps_per_second': 2.373, 'epoch': 0}
{'loss': 3.8134, 'grad_norm': 93.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'eval_loss': 1.458141565322876, 'eval_runtime': 102.7017, 'eval_samples_per_second': 18.948, 'eval_steps_per_second': 2.376, 'epoch': 0.0}
{'loss': 3.936, 'grad_norm': 91.5, 'learning_rate': 2e-08, 'epoch': 0.0}
{'eval_loss': 1.4577350616455078, 'eval_runtime': 102.6257, 'eval_samples_per_second': 18.962, 'eval_steps_per_second': 2.378, 'epoch': 0.0}
{'loss': 3.9432, 'grad_norm': 94.0, 'learning_rate': 4e-08, 'epoch': 0.0}
{'eval_loss': 1.4593775272369385, 'eval_runtime': 102.5629, 'eval_samples_per_second': 18.974, 'eval_steps_per_second': 2.379, 'epoch': 0.0}
{'loss': 4.5415, 'grad_norm': 123.0, 'learning_rate': 6e-08, 'epoch': 0.0}
{'eval_loss': 1.458349585533142, 'eval_runtime': 102.5376, 'eval_samples_per_second': 18.978, 'eval_steps_per_second': 2.38, 'epoch': 0.0}
{'loss': 3.8066, 'grad_norm': 109.5, 'learning_rate': 8e-08, 'epoch': 0.0}
{'eval_loss': 1.458713412284851, 'eval_runtime': 102.5341, 'eval_samples_per_second': 18.979, 'eval_steps_per_second': 2.38, 'epoch': 0.0}
{'loss': 3.0997, 'grad_norm': 82.0, 'learning_rate': 1e-07, 'epoch': 0.0}
{'eval_loss': 1.4582011699676514, 'eval_runtime': 102.5365, 'eval_samples_per_second': 18.979, 'eval_steps_per_second': 2.38, 'epoch': 0.0}
{'loss': 3.4823, 'grad_norm': 93.0, 'learning_rate': 1.2e-07, 'epoch': 0.0}
{'eval_loss': 1.4582135677337646, 'eval_runtime': 102.5629, 'eval_samples_per_second': 18.974, 'eval_steps_per_second': 2.379, 'epoch': 0.0}
{'loss': 3.8895, 'grad_norm': 105.0, 'learning_rate': 1.4e-07, 'epoch': 0.0}
{'eval_loss': 1.4579744338989258, 'eval_runtime': 102.5508, 'eval_samples_per_second': 18.976, 'eval_steps_per_second': 2.379, 'epoch': 0.0}
{'loss': 3.4794, 'grad_norm': 85.0, 'learning_rate': 1.6e-07, 'epoch': 0.0}
{'eval_loss': 1.457381010055542, 'eval_runtime': 102.5102, 'eval_samples_per_second': 18.983, 'eval_steps_per_second': 2.38, 'epoch': 0.0}
{'loss': 3.5848, 'grad_norm': 85.5, 'learning_rate': 1.8e-07, 'epoch': 0.0}
{'eval_loss': 1.4582420587539673, 'eval_runtime': 102.5047, 'eval_samples_per_second': 18.985, 'eval_steps_per_second': 2.38, 'epoch': 0.0}
{'train_runtime': 1209.9875, 'train_samples_per_second': 0.264, 'train_steps_per_second': 0.008, 'train_loss': 3.7576327085494996, 'epoch': 0.0}

-------------------------
Student evaluation for 1: 1.3841689825057983
Ensemble evaluation for 1: 1.3836259841918945
Teacher evaluation for 1: 1.0332053899765015
-------------------------
==================================================
Ending Round 1 at: 2025-05-29 19:04:05
Completed in: 21m 5s
Total training time: 32m 42s
==================================================


==================================================
Starting Round 2 at: 2025-05-29 19:04:06
==================================================
Round '2' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-29/run_6/round_2
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|                                                                                                                                                      | 0/10 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 44. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [27:32<00:00, 149.34s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [28:08<00:00, 168.88s/it]
{'eval_loss': 1.458499550819397, 'eval_runtime': 143.0325, 'eval_samples_per_second': 13.605, 'eval_steps_per_second': 1.706, 'epoch': 0}
{'loss': 3.4711, 'grad_norm': 56.0, 'learning_rate': 0.0, 'epoch': 0.0}
{'eval_loss': 1.458499550819397, 'eval_runtime': 142.8349, 'eval_samples_per_second': 13.624, 'eval_steps_per_second': 1.708, 'epoch': 0.0}
{'loss': 3.7569, 'grad_norm': 58.0, 'learning_rate': 2e-08, 'epoch': 0.0}
{'eval_loss': 1.4581743478775024, 'eval_runtime': 142.6932, 'eval_samples_per_second': 13.638, 'eval_steps_per_second': 1.71, 'epoch': 0.0}
{'loss': 3.8077, 'grad_norm': 46.5, 'learning_rate': 4e-08, 'epoch': 0.0}
{'eval_loss': 1.4591015577316284, 'eval_runtime': 142.5471, 'eval_samples_per_second': 13.652, 'eval_steps_per_second': 1.712, 'epoch': 0.0}
{'loss': 3.8054, 'grad_norm': 67.0, 'learning_rate': 6e-08, 'epoch': 0.0}
{'eval_loss': 1.4585047960281372, 'eval_runtime': 142.638, 'eval_samples_per_second': 13.643, 'eval_steps_per_second': 1.711, 'epoch': 0.0}
{'loss': 5.2777, 'grad_norm': 106.5, 'learning_rate': 8e-08, 'epoch': 0.0}
{'eval_loss': 1.4577075242996216, 'eval_runtime': 142.6848, 'eval_samples_per_second': 13.638, 'eval_steps_per_second': 1.71, 'epoch': 0.0}
{'loss': 3.9587, 'grad_norm': 66.5, 'learning_rate': 1e-07, 'epoch': 0.0}
{'eval_loss': 1.4581100940704346, 'eval_runtime': 142.6124, 'eval_samples_per_second': 13.645, 'eval_steps_per_second': 1.711, 'epoch': 0.0}
{'loss': 4.1845, 'grad_norm': 74.5, 'learning_rate': 1.2e-07, 'epoch': 0.0}
{'eval_loss': 1.4587856531143188, 'eval_runtime': 142.6763, 'eval_samples_per_second': 13.639, 'eval_steps_per_second': 1.71, 'epoch': 0.0}
{'loss': 3.6639, 'grad_norm': 55.5, 'learning_rate': 1.4e-07, 'epoch': 0.0}
{'eval_loss': 1.4585161209106445, 'eval_runtime': 142.7048, 'eval_samples_per_second': 13.637, 'eval_steps_per_second': 1.71, 'epoch': 0.0}
{'loss': 3.6213, 'grad_norm': 69.5, 'learning_rate': 1.6e-07, 'epoch': 0.0}
{'eval_loss': 1.4582583904266357, 'eval_runtime': 142.6401, 'eval_samples_per_second': 13.643, 'eval_steps_per_second': 1.711, 'epoch': 0.0}
{'loss': 3.0403, 'grad_norm': 56.0, 'learning_rate': 1.8e-07, 'epoch': 0.0}
{'eval_loss': 1.4583145380020142, 'eval_runtime': 142.6515, 'eval_samples_per_second': 13.642, 'eval_steps_per_second': 1.71, 'epoch': 0.0}
{'train_runtime': 1652.429, 'train_samples_per_second': 0.194, 'train_steps_per_second': 0.006, 'train_loss': 3.858737587928772, 'epoch': 0.0}

-------------------------
Student evaluation for 2: 1.3837429285049438
Ensemble evaluation for 2: 1.383787989616394
Teacher evaluation for 2: 1.0332053899765015
-------------------------
==================================================
Ending Round 2 at: 2025-05-29 19:32:24
Completed in: 28m 18s
Total training time: 61m 2s
==================================================


==================================================
Starting Round 3 at: 2025-05-29 19:32:25
==================================================
Round '3' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-29/run_6/round_3
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
  0%|                                                                                                                                                      | 0/10 [00:00<?, ?it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 66. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [34:57<00:00, 189.88s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Traceback (most recent call last):                                                                                                                                                
{'eval_loss': 1.4584943056106567, 'eval_runtime': 183.0944, 'eval_samples_per_second': 10.628, 'eval_steps_per_second': 1.333, 'epoch': 0}
{'loss': 2.7393, 'grad_norm': 31.625, 'learning_rate': 0.0, 'epoch': 0.0}
{'eval_loss': 1.4584943056106567, 'eval_runtime': 182.7189, 'eval_samples_per_second': 10.65, 'eval_steps_per_second': 1.335, 'epoch': 0.0}
{'loss': 3.4278, 'grad_norm': 37.75, 'learning_rate': 2e-08, 'epoch': 0.0}
{'eval_loss': 1.4585623741149902, 'eval_runtime': 182.6414, 'eval_samples_per_second': 10.655, 'eval_steps_per_second': 1.336, 'epoch': 0.0}
{'loss': 3.4435, 'grad_norm': 39.75, 'learning_rate': 4e-08, 'epoch': 0.0}
{'eval_loss': 1.4588342905044556, 'eval_runtime': 182.5482, 'eval_samples_per_second': 10.66, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'loss': 3.4999, 'grad_norm': 45.75, 'learning_rate': 6e-08, 'epoch': 0.0}
{'eval_loss': 1.4581202268600464, 'eval_runtime': 182.5001, 'eval_samples_per_second': 10.663, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'loss': 3.9922, 'grad_norm': 56.5, 'learning_rate': 8e-08, 'epoch': 0.0}
{'eval_loss': 1.4582449197769165, 'eval_runtime': 182.6505, 'eval_samples_per_second': 10.654, 'eval_steps_per_second': 1.336, 'epoch': 0.0}
{'loss': 3.8667, 'grad_norm': 43.5, 'learning_rate': 1e-07, 'epoch': 0.0}
{'eval_loss': 1.459145188331604, 'eval_runtime': 182.5525, 'eval_samples_per_second': 10.66, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'loss': 3.8343, 'grad_norm': 44.25, 'learning_rate': 1.2e-07, 'epoch': 0.0}
{'eval_loss': 1.4585522413253784, 'eval_runtime': 182.5661, 'eval_samples_per_second': 10.659, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'loss': 4.1687, 'grad_norm': 42.0, 'learning_rate': 1.4e-07, 'epoch': 0.0}
{'eval_loss': 1.4574992656707764, 'eval_runtime': 182.524, 'eval_samples_per_second': 10.662, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'loss': 3.8447, 'grad_norm': 57.5, 'learning_rate': 1.6e-07, 'epoch': 0.0}
{'eval_loss': 1.4584598541259766, 'eval_runtime': 182.4805, 'eval_samples_per_second': 10.664, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'loss': 3.909, 'grad_norm': 46.5, 'learning_rate': 1.8e-07, 'epoch': 0.0}
{'eval_loss': 1.4587492942810059, 'eval_runtime': 182.5544, 'eval_samples_per_second': 10.66, 'eval_steps_per_second': 1.337, 'epoch': 0.0}
{'train_runtime': 2097.7824, 'train_samples_per_second': 0.153, 'train_steps_per_second': 0.005, 'train_loss': 3.672588658332825, 'epoch': 0.0}
  File "/h/klambert/slm_ensembles/train.py", line 299, in <module>
    main()
  File "/h/klambert/slm_ensembles/train.py", line 237, in main
    trainer.train()
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2725, in _inner_training_loop
    self.control = self.callback_handler.on_train_end(args, self.state, self.control)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer_callback.py", line 509, in on_train_end
    return self.call_event("on_train_end", args, state, control)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer_callback.py", line 556, in call_event
    result = getattr(callback, event)(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/integrations/integration_utils.py", line 967, in on_train_end
    with artifact.new_file(f.name, mode="wb") as fa:
  File "/pkgs/python-3.10.12/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/wandb/sdk/artifacts/artifact.py", line 1355, in new_file
    with util.fsync_open(path, mode, encoding) as f:
  File "/pkgs/python-3.10.12/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/wandb/util.py", line 1577, in fsync_open
    os.fsync(f.fileno())
KeyboardInterrupt
