Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Teacher model evaluation: {'eval_loss': 1.3539468194424984}
No prior ensemble loaded

==================================================
Starting Round 0 at: 2025-05-19 18:45:12
==================================================
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: WARNING The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
  0%|          | 0/1000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
                                                    
{'loss': 3.8146, 'grad_norm': 119.5, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.0}
{'loss': 2.9451, 'grad_norm': 42.0, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.0}
{'loss': 2.4483, 'grad_norm': 43.75, 'learning_rate': 1.16e-05, 'epoch': 0.0}
{'loss': 2.3365, 'grad_norm': 27.0, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.0}
{'loss': 2.1857, 'grad_norm': 21.0, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.0}
{'loss': 2.235, 'grad_norm': 30.25, 'learning_rate': 1.9810526315789476e-05, 'epoch': 0.0}
{'loss': 2.1501, 'grad_norm': 38.75, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.01}
{'loss': 1.965, 'grad_norm': 29.0, 'learning_rate': 1.9389473684210525e-05, 'epoch': 0.01}
{'loss': 2.3859, 'grad_norm': 21.125, 'learning_rate': 1.9178947368421055e-05, 'epoch': 0.01}
{'loss': 2.2128, 'grad_norm': 21.0, 'learning_rate': 1.8968421052631582e-05, 'epoch': 0.01}
                                                 
{'eval_loss': 1.3912334442138672, 'eval_runtime': 58.2641, 'eval_samples_per_second': 33.4, 'eval_steps_per_second': 4.188, 'epoch': 0.01}
{'loss': 1.8852, 'grad_norm': 24.125, 'learning_rate': 1.8757894736842105e-05, 'epoch': 0.01}
{'loss': 1.9206, 'grad_norm': 20.125, 'learning_rate': 1.8547368421052635e-05, 'epoch': 0.01}
{'loss': 2.0932, 'grad_norm': 39.0, 'learning_rate': 1.8336842105263158e-05, 'epoch': 0.01}
{'loss': 2.3121, 'grad_norm': 25.5, 'learning_rate': 1.8126315789473685e-05, 'epoch': 0.01}
{'loss': 2.1072, 'grad_norm': 12.0625, 'learning_rate': 1.7915789473684214e-05, 'epoch': 0.01}
{'loss': 2.4528, 'grad_norm': 17.0, 'learning_rate': 1.7705263157894738e-05, 'epoch': 0.01}
{'loss': 1.9218, 'grad_norm': 18.625, 'learning_rate': 1.7494736842105264e-05, 'epoch': 0.01}
{'loss': 2.0684, 'grad_norm': 16.5, 'learning_rate': 1.728421052631579e-05, 'epoch': 0.01}
{'loss': 1.9773, 'grad_norm': 17.125, 'learning_rate': 1.7073684210526317e-05, 'epoch': 0.02}
{'loss': 2.0511, 'grad_norm': 14.9375, 'learning_rate': 1.6863157894736844e-05, 'epoch': 0.02}
{'eval_loss': 1.3862831592559814, 'eval_runtime': 58.2534, 'eval_samples_per_second': 33.406, 'eval_steps_per_second': 4.189, 'epoch': 0.02}
{'loss': 1.993, 'grad_norm': 14.4375, 'learning_rate': 1.665263157894737e-05, 'epoch': 0.02}
{'loss': 2.2692, 'grad_norm': 21.0, 'learning_rate': 1.6442105263157897e-05, 'epoch': 0.02}
{'loss': 1.9138, 'grad_norm': 18.625, 'learning_rate': 1.6231578947368423e-05, 'epoch': 0.02}
{'loss': 1.9387, 'grad_norm': 23.875, 'learning_rate': 1.6021052631578947e-05, 'epoch': 0.02}
{'loss': 2.2547, 'grad_norm': 21.5, 'learning_rate': 1.5810526315789473e-05, 'epoch': 0.02}
{'loss': 1.9688, 'grad_norm': 27.0, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.02}
{'loss': 2.257, 'grad_norm': 21.875, 'learning_rate': 1.5389473684210526e-05, 'epoch': 0.02}
{'loss': 1.9982, 'grad_norm': 22.375, 'learning_rate': 1.5178947368421053e-05, 'epoch': 0.02}
{'loss': 2.0527, 'grad_norm': 18.5, 'learning_rate': 1.4968421052631581e-05, 'epoch': 0.02}
{'loss': 2.0083, 'grad_norm': 24.875, 'learning_rate': 1.4757894736842106e-05, 'epoch': 0.02}
{'eval_loss': 1.3843629360198975, 'eval_runtime': 58.2322, 'eval_samples_per_second': 33.418, 'eval_steps_per_second': 4.19, 'epoch': 0.02}
{'loss': 2.0237, 'grad_norm': 17.5, 'learning_rate': 1.4547368421052632e-05, 'epoch': 0.03}
{'loss': 1.9785, 'grad_norm': 17.625, 'learning_rate': 1.433684210526316e-05, 'epoch': 0.03}
{'loss': 1.9154, 'grad_norm': 16.25, 'learning_rate': 1.4126315789473686e-05, 'epoch': 0.03}
{'loss': 1.8078, 'grad_norm': 15.75, 'learning_rate': 1.3915789473684212e-05, 'epoch': 0.03}
{'loss': 1.9936, 'grad_norm': 22.375, 'learning_rate': 1.3705263157894737e-05, 'epoch': 0.03}
{'loss': 2.0772, 'grad_norm': 17.75, 'learning_rate': 1.3494736842105265e-05, 'epoch': 0.03}
{'loss': 1.9571, 'grad_norm': 20.75, 'learning_rate': 1.328421052631579e-05, 'epoch': 0.03}
{'loss': 2.1063, 'grad_norm': 16.25, 'learning_rate': 1.3073684210526317e-05, 'epoch': 0.03}
{'loss': 2.1303, 'grad_norm': 20.125, 'learning_rate': 1.2863157894736845e-05, 'epoch': 0.03}
{'loss': 2.2034, 'grad_norm': 21.25, 'learning_rate': 1.265263157894737e-05, 'epoch': 0.03}
{'eval_loss': 1.3859522342681885, 'eval_runtime': 58.235, 'eval_samples_per_second': 33.416, 'eval_steps_per_second': 4.19, 'epoch': 0.03}
{'loss': 2.1152, 'grad_norm': 27.5, 'learning_rate': 1.2442105263157895e-05, 'epoch': 0.03}
{'loss': 2.1232, 'grad_norm': 14.0625, 'learning_rate': 1.2231578947368421e-05, 'epoch': 0.03}
{'loss': 1.8939, 'grad_norm': 15.5625, 'learning_rate': 1.202105263157895e-05, 'epoch': 0.04}
{'loss': 2.1366, 'grad_norm': 20.125, 'learning_rate': 1.1810526315789474e-05, 'epoch': 0.04}
{'loss': 1.9246, 'grad_norm': 15.375, 'learning_rate': 1.16e-05, 'epoch': 0.04}
{'loss': 1.8196, 'grad_norm': 14.4375, 'learning_rate': 1.1389473684210527e-05, 'epoch': 0.04}
{'loss': 2.1463, 'grad_norm': 23.75, 'learning_rate': 1.1178947368421054e-05, 'epoch': 0.04}
{'loss': 2.0111, 'grad_norm': 15.4375, 'learning_rate': 1.0968421052631579e-05, 'epoch': 0.04}
{'loss': 1.9449, 'grad_norm': 25.375, 'learning_rate': 1.0757894736842107e-05, 'epoch': 0.04}
{'loss': 1.9345, 'grad_norm': 19.125, 'learning_rate': 1.0547368421052633e-05, 'epoch': 0.04}
{'eval_loss': 1.3866159915924072, 'eval_runtime': 58.2508, 'eval_samples_per_second': 33.407, 'eval_steps_per_second': 4.189, 'epoch': 0.04}
{'loss': 2.0762, 'grad_norm': 15.5, 'learning_rate': 1.0336842105263158e-05, 'epoch': 0.04}
{'loss': 1.9983, 'grad_norm': 14.625, 'learning_rate': 1.0126315789473685e-05, 'epoch': 0.04}
{'loss': 2.0426, 'grad_norm': 17.75, 'learning_rate': 9.915789473684211e-06, 'epoch': 0.04}
{'loss': 1.9561, 'grad_norm': 15.3125, 'learning_rate': 9.705263157894738e-06, 'epoch': 0.04}
{'loss': 2.0372, 'grad_norm': 18.875, 'learning_rate': 9.494736842105265e-06, 'epoch': 0.05}
{'loss': 1.9505, 'grad_norm': 20.75, 'learning_rate': 9.28421052631579e-06, 'epoch': 0.05}
{'loss': 2.0681, 'grad_norm': 19.75, 'learning_rate': 9.073684210526316e-06, 'epoch': 0.05}
{'loss': 2.0456, 'grad_norm': 21.875, 'learning_rate': 8.863157894736842e-06, 'epoch': 0.05}
{'loss': 1.8343, 'grad_norm': 32.25, 'learning_rate': 8.652631578947369e-06, 'epoch': 0.05}
{'loss': 2.0306, 'grad_norm': 23.125, 'learning_rate': 8.442105263157896e-06, 'epoch': 0.05}
{'eval_loss': 1.3846559524536133, 'eval_runtime': 58.3349, 'eval_samples_per_second': 33.359, 'eval_steps_per_second': 4.183, 'epoch': 0.05}
{'loss': 1.9889, 'grad_norm': 14.0625, 'learning_rate': 8.231578947368422e-06, 'epoch': 0.05}
{'loss': 2.1604, 'grad_norm': 20.125, 'learning_rate': 8.021052631578949e-06, 'epoch': 0.05}
{'loss': 1.848, 'grad_norm': 22.875, 'learning_rate': 7.810526315789474e-06, 'epoch': 0.05}
{'loss': 2.0281, 'grad_norm': 16.875, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.05}
{'loss': 2.0329, 'grad_norm': 12.5625, 'learning_rate': 7.3894736842105275e-06, 'epoch': 0.05}
{'loss': 1.8453, 'grad_norm': 18.5, 'learning_rate': 7.178947368421053e-06, 'epoch': 0.05}
{'loss': 1.9464, 'grad_norm': 12.375, 'learning_rate': 6.96842105263158e-06, 'epoch': 0.06}
{'loss': 1.857, 'grad_norm': 16.875, 'learning_rate': 6.7578947368421054e-06, 'epoch': 0.06}
{'loss': 1.8938, 'grad_norm': 31.25, 'learning_rate': 6.547368421052632e-06, 'epoch': 0.06}
{'loss': 2.0296, 'grad_norm': 13.875, 'learning_rate': 6.336842105263158e-06, 'epoch': 0.06}
{'eval_loss': 1.3846569061279297, 'eval_runtime': 58.2269, 'eval_samples_per_second': 33.421, 'eval_steps_per_second': 4.191, 'epoch': 0.06}
{'loss': 2.1034, 'grad_norm': 19.0, 'learning_rate': 6.126315789473685e-06, 'epoch': 0.06}
{'loss': 2.0085, 'grad_norm': 17.375, 'learning_rate': 5.915789473684212e-06, 'epoch': 0.06}
{'loss': 1.9474, 'grad_norm': 15.9375, 'learning_rate': 5.705263157894737e-06, 'epoch': 0.06}
{'loss': 2.1012, 'grad_norm': 25.375, 'learning_rate': 5.494736842105264e-06, 'epoch': 0.06}
{'loss': 1.8998, 'grad_norm': 15.125, 'learning_rate': 5.2842105263157896e-06, 'epoch': 0.06}
{'loss': 1.9237, 'grad_norm': 19.375, 'learning_rate': 5.073684210526316e-06, 'epoch': 0.06}
{'loss': 1.8251, 'grad_norm': 15.5, 'learning_rate': 4.863157894736843e-06, 'epoch': 0.06}
{'loss': 1.8951, 'grad_norm': 12.9375, 'learning_rate': 4.652631578947368e-06, 'epoch': 0.06}
{'loss': 1.9556, 'grad_norm': 19.25, 'learning_rate': 4.442105263157896e-06, 'epoch': 0.07}
{'loss': 1.9114, 'grad_norm': 21.25, 'learning_rate': 4.2315789473684215e-06, 'epoch': 0.07}
{'eval_loss': 1.3859093189239502, 'eval_runtime': 58.3772, 'eval_samples_per_second': 33.335, 'eval_steps_per_second': 4.18, 'epoch': 0.07}
{'loss': 1.9388, 'grad_norm': 21.75, 'learning_rate': 4.021052631578948e-06, 'epoch': 0.07}
{'loss': 2.0921, 'grad_norm': 15.125, 'learning_rate': 3.810526315789474e-06, 'epoch': 0.07}
{'loss': 2.1396, 'grad_norm': 14.75, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.07}
{'loss': 1.8237, 'grad_norm': 12.75, 'learning_rate': 3.3894736842105264e-06, 'epoch': 0.07}
{'loss': 1.8225, 'grad_norm': 16.875, 'learning_rate': 3.178947368421053e-06, 'epoch': 0.07}
{'loss': 1.8477, 'grad_norm': 17.5, 'learning_rate': 2.9684210526315795e-06, 'epoch': 0.07}
{'loss': 1.9003, 'grad_norm': 24.125, 'learning_rate': 2.7578947368421056e-06, 'epoch': 0.07}
{'loss': 1.9335, 'grad_norm': 24.625, 'learning_rate': 2.5473684210526317e-06, 'epoch': 0.07}
{'loss': 1.9917, 'grad_norm': 33.75, 'learning_rate': 2.3368421052631583e-06, 'epoch': 0.07}
{'loss': 1.893, 'grad_norm': 22.25, 'learning_rate': 2.1263157894736844e-06, 'epoch': 0.07}
{'eval_loss': 1.3843439817428589, 'eval_runtime': 58.3721, 'eval_samples_per_second': 33.338, 'eval_steps_per_second': 4.18, 'epoch': 0.07}
{'loss': 2.1922, 'grad_norm': 19.25, 'learning_rate': 1.9157894736842105e-06, 'epoch': 0.08}
{'loss': 2.0731, 'grad_norm': 27.75, 'learning_rate': 1.705263157894737e-06, 'epoch': 0.08}
{'loss': 2.0196, 'grad_norm': 23.625, 'learning_rate': 1.4947368421052632e-06, 'epoch': 0.08}
{'loss': 1.9046, 'grad_norm': 13.625, 'learning_rate': 1.2842105263157895e-06, 'epoch': 0.08}
{'loss': 1.92, 'grad_norm': 17.25, 'learning_rate': 1.0736842105263159e-06, 'epoch': 0.08}
{'loss': 2.1428, 'grad_norm': 20.625, 'learning_rate': 8.631578947368421e-07, 'epoch': 0.08}
{'loss': 2.1291, 'grad_norm': 25.375, 'learning_rate': 6.526315789473684e-07, 'epoch': 0.08}
{'loss': 2.0403, 'grad_norm': 12.6875, 'learning_rate': 4.421052631578947e-07, 'epoch': 0.08}
{'loss': 1.9471, 'grad_norm': 21.5, 'learning_rate': 2.315789473684211e-07, 'epoch': 0.08}
{'loss': 1.9584, 'grad_norm': 18.875, 'learning_rate': 2.1052631578947368e-08, 'epoch': 0.08}
{'eval_loss': 1.3850890398025513, 'eval_runtime': 58.3557, 'eval_samples_per_second': 33.347, 'eval_steps_per_second': 4.181, 'epoch': 0.08}
{'train_runtime': 3736.0, 'train_samples_per_second': 4.283, 'train_steps_per_second': 0.268, 'train_loss': 2.0531758499145507, 'epoch': 0.08}
Round 0 student evaluation: {'eval_loss': 1.4384994127422388}
Ensemble evaluation after round 0: {'eval_loss': 1.4384994127422388}
Round 0 completed in: 65m 7s
Total training time so far: 67m 24s

==================================================
Starting Round 1 at: 2025-05-19 19:50:22
==================================================
Truncating train dataset: 100%|██████████| 192701/192701 [01:34<00:00, 2047.23 examples/s] 
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.
  0%|          | 0/1000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/h/klambert/slm_ensembles/train.py", line 419, in <module>
    main()
  File "/h/klambert/slm_ensembles/train.py", line 288, in main
    trainer.train()
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/h/klambert/slm_ensembles/train.py", line 91, in compute_loss
    student_logits = model(input_ids, attention_mask=attention_mask).logits
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
    causal_mask = self._update_causal_mask(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 613, in _update_causal_mask
    if AttentionMaskConverter._ignore_causal_mask_sdpa(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 288, in _ignore_causal_mask_sdpa
    elif not is_tracing and torch.all(attention_mask == 1):
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
