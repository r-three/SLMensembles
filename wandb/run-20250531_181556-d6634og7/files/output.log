Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.

==================================================
Starting Round 0 at: 2025-05-31 18:16:05
==================================================
Round '0' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-31/run_1/round_0
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [32:57<00:00, 180.01s/it]Traceback (most recent call last):
  File "/h/klambert/slm_ensembles/train.py", line 313, in <module>                                                                                                                                                                                                     
{'eval_loss': 0.9272032976150513, 'eval_runtime': 174.9595, 'eval_samples_per_second': 11.123, 'eval_steps_per_second': 1.395, 'epoch': 0}
{'loss': 2.0805, 'grad_norm': 23.125, 'learning_rate': 0.0, 'epoch': 0.0}
{'eval_loss': 0.9272032976150513, 'eval_runtime': 175.4193, 'eval_samples_per_second': 11.093, 'eval_steps_per_second': 1.391, 'epoch': 0.0}
{'loss': 1.7785, 'grad_norm': 21.0, 'learning_rate': 2e-08, 'epoch': 0.0}
{'eval_loss': 0.9272081851959229, 'eval_runtime': 175.1204, 'eval_samples_per_second': 11.112, 'eval_steps_per_second': 1.393, 'epoch': 0.0}
{'loss': 2.135, 'grad_norm': 25.375, 'learning_rate': 4e-08, 'epoch': 0.0}
{'eval_loss': 0.9270830154418945, 'eval_runtime': 175.0677, 'eval_samples_per_second': 11.116, 'eval_steps_per_second': 1.394, 'epoch': 0.0}
{'loss': 1.5352, 'grad_norm': 20.5, 'learning_rate': 6e-08, 'epoch': 0.0}
{'eval_loss': 0.9273494482040405, 'eval_runtime': 174.9706, 'eval_samples_per_second': 11.122, 'eval_steps_per_second': 1.395, 'epoch': 0.0}
{'loss': 2.1346, 'grad_norm': 29.5, 'learning_rate': 8e-08, 'epoch': 0.0}
{'eval_loss': 0.9269324541091919, 'eval_runtime': 174.9679, 'eval_samples_per_second': 11.122, 'eval_steps_per_second': 1.395, 'epoch': 0.0}
{'loss': 1.3285, 'grad_norm': 21.625, 'learning_rate': 1e-07, 'epoch': 0.0}
{'eval_loss': 0.9270846247673035, 'eval_runtime': 175.0937, 'eval_samples_per_second': 11.114, 'eval_steps_per_second': 1.394, 'epoch': 0.0}
{'loss': 1.7089, 'grad_norm': 18.625, 'learning_rate': 1.2e-07, 'epoch': 0.0}
{'eval_loss': 0.9272142052650452, 'eval_runtime': 175.1473, 'eval_samples_per_second': 11.111, 'eval_steps_per_second': 1.393, 'epoch': 0.0}
{'loss': 1.915, 'grad_norm': 25.375, 'learning_rate': 1.4e-07, 'epoch': 0.0}
{'eval_loss': 0.9273146986961365, 'eval_runtime': 175.0976, 'eval_samples_per_second': 11.114, 'eval_steps_per_second': 1.394, 'epoch': 0.0}
{'loss': 1.2979, 'grad_norm': 17.75, 'learning_rate': 1.6e-07, 'epoch': 0.0}
{'eval_loss': 0.927262008190155, 'eval_runtime': 175.0954, 'eval_samples_per_second': 11.114, 'eval_steps_per_second': 1.394, 'epoch': 0.0}
{'loss': 1.306, 'grad_norm': 22.125, 'learning_rate': 1.8e-07, 'epoch': 0.0}
{'eval_loss': 0.927190899848938, 'eval_runtime': 175.1084, 'eval_samples_per_second': 11.113, 'eval_steps_per_second': 1.393, 'epoch': 0.0}
    main()
  File "/h/klambert/slm_ensembles/train.py", line 250, in main
    trainer.train()
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2627, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3103, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3211, in _save_checkpoint
    self._save_optimizer_and_scheduler(output_dir)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3351, in _save_optimizer_and_scheduler
    torch.save(self.lr_scheduler.state_dict(), os.path.join(output_dir, SCHEDULER_NAME))
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/serialization.py", line 943, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/serialization.py", line 810, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/serialization.py", line 781, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name, _compute_crc32))
RuntimeError: File /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-31/run_1/round_0/checkpoint-10/scheduler.pt cannot be opened.
