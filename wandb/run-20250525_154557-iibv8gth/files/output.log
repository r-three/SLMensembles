Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.

==================================================
Starting Round 0 at: 2025-05-25 15:46:21
==================================================
Round '0' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_4/round_0
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
[34m[1mwandb[0m: [33mWARNING[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:33<00:00, 50.69s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         
{'eval_loss': 1.430925726890564, 'eval_runtime': 50.5164, 'eval_samples_per_second': 38.522, 'eval_steps_per_second': 4.83, 'epoch': 0.0}
{'eval_loss': 1.4008212089538574, 'eval_runtime': 50.7668, 'eval_samples_per_second': 38.332, 'eval_steps_per_second': 4.806, 'epoch': 0.0}
{'eval_loss': 1.3869866132736206, 'eval_runtime': 50.9709, 'eval_samples_per_second': 38.179, 'eval_steps_per_second': 4.787, 'epoch': 0.0}
{'eval_loss': 1.3833584785461426, 'eval_runtime': 51.0585, 'eval_samples_per_second': 38.113, 'eval_steps_per_second': 4.779, 'epoch': 0.0}
{'eval_loss': 1.3811849355697632, 'eval_runtime': 51.0094, 'eval_samples_per_second': 38.15, 'eval_steps_per_second': 4.783, 'epoch': 0.0}
{'eval_loss': 1.3802059888839722, 'eval_runtime': 51.0064, 'eval_samples_per_second': 38.152, 'eval_steps_per_second': 4.784, 'epoch': 0.0}
{'eval_loss': 1.3803492784500122, 'eval_runtime': 51.0368, 'eval_samples_per_second': 38.129, 'eval_steps_per_second': 4.781, 'epoch': 0.0}
{'eval_loss': 1.3804905414581299, 'eval_runtime': 50.9921, 'eval_samples_per_second': 38.163, 'eval_steps_per_second': 4.785, 'epoch': 0.0}
{'eval_loss': 1.380103349685669, 'eval_runtime': 50.9739, 'eval_samples_per_second': 38.176, 'eval_steps_per_second': 4.787, 'epoch': 0.0}
{'loss': 0.3382, 'grad_norm': 7.15625, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
{'eval_loss': 1.3805174827575684, 'eval_runtime': 50.9976, 'eval_samples_per_second': 38.159, 'eval_steps_per_second': 4.785, 'epoch': 0.0}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:49<00:00, 50.69s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 529.1311, 'train_samples_per_second': 0.038, 'train_steps_per_second': 0.019, 'train_loss': 0.3382471323013306, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 12. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [09:20<00:00, 56.04s/it]

-------------------------
Student evaluation for 0: 1.3465190320338716, perplexity: 3.8440210819244385, tokens: 1024012
Ensemble evaluation for 0: 1.3465190320338716, perplexity: 3.8440210819244385, tokens: 1024012
Teacher evaluation for 0: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 0 at: 2025-05-25 15:59:16
Completed in: 12m 55s
Total training time: 13m 18s
==================================================


==================================================
Starting Round 1 at: 2025-05-25 15:59:17
==================================================
Round '1' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_4/round_1
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 10%|███████████████████████▌                                                                                                                                                                                                                   | 1/10 [01:41<00:04,  2.08it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 14. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 14. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                          
{'eval_loss': 1.3769880533218384, 'eval_runtime': 101.2928, 'eval_samples_per_second': 19.212, 'eval_steps_per_second': 2.409, 'epoch': 0.0}
 30%|██████████████████████████████████████████████████████████████████████▌                                                                                                                                                                    | 3/10 [03:25<09:16, 79.55s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 15. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 15. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 16/244 [00:06<01:34,  2.41it/s]
{'eval_loss': 1.372053861618042, 'eval_runtime': 101.2994, 'eval_samples_per_second': 19.21, 'eval_steps_per_second': 2.409, 'epoch': 0.0}
 40%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 4/10 [05:07<08:49, 88.26s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 12/244 [00:04<01:35,  2.42it/s]
{'eval_loss': 1.3729573488235474, 'eval_runtime': 101.207, 'eval_samples_per_second': 19.228, 'eval_steps_per_second': 2.411, 'epoch': 0.0}
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                     | 5/10 [06:48<07:45, 93.10s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 17. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 17. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.          | 8/244 [00:02<01:34,  2.49it/s]
{'eval_loss': 1.373793363571167, 'eval_runtime': 101.273, 'eval_samples_per_second': 19.215, 'eval_steps_per_second': 2.409, 'epoch': 0.0}
 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                              | 6/10 [08:30<06:23, 95.97s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 18. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 18. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.          | 4/244 [00:01<01:21,  2.95it/s]
{'eval_loss': 1.3736733198165894, 'eval_runtime': 101.1558, 'eval_samples_per_second': 19.238, 'eval_steps_per_second': 2.412, 'epoch': 0.0}
 70%|███████████████████▌        | 7/10 [10:11<04:53, 97.81s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                          
{'eval_loss': 1.3742005825042725, 'eval_runtime': 101.2185, 'eval_samples_per_second': 19.226, 'eval_steps_per_second': 2.411, 'epoch': 0.0}
 80%|██████████████████████▍     | 8/10 [11:53<03:18, 99.03s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.374455213546753, 'eval_runtime': 101.2108, 'eval_samples_per_second': 19.227, 'eval_steps_per_second': 2.411, 'epoch': 0.0}
 90%|█████████████████████████▏  | 9/10 [13:35<01:39, 99.83s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3744531869888306, 'eval_runtime': 101.2022, 'eval_samples_per_second': 19.229, 'eval_steps_per_second': 2.411, 'epoch': 0.0}
100%|██████████████████████████| 10/10 [15:16<00:00, 100.37s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3746534585952759, 'eval_runtime': 101.1693, 'eval_samples_per_second': 19.235, 'eval_steps_per_second': 2.412, 'epoch': 0.0}
{'loss': 0.3461, 'grad_norm': 3.25, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 23. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████| 10/10 [16:57<00:00, 100.37s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3749257326126099, 'eval_runtime': 101.1944, 'eval_samples_per_second': 19.23, 'eval_steps_per_second': 2.411, 'epoch': 0.0}
100%|██████████████████████████| 10/10 [17:15<00:00, 100.37s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 1035.4009, 'train_samples_per_second': 0.019, 'train_steps_per_second': 0.01, 'train_loss': 0.34608092308044436, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 25. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████| 10/10 [17:48<00:00, 106.88s/it]

-------------------------
Student evaluation for 1: 1.3460090801973177, perplexity: 3.842061758041382, tokens: 1024012
Ensemble evaluation for 1: 1.3415119746555002, perplexity: 3.824822187423706, tokens: 1024012
Teacher evaluation for 1: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 1 at: 2025-05-25 16:21:22
Completed in: 22m 5s
Total training time: 35m 24s
==================================================


==================================================
Starting Round 2 at: 2025-05-25 16:21:23
==================================================
Round '2' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_4/round_2
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 20%|█████▌                      | 2/10 [02:21<11:07, 83.41s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 27. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 27. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3761200904846191, 'eval_runtime': 140.9904, 'eval_samples_per_second': 13.802, 'eval_steps_per_second': 1.731, 'epoch': 0.0}
 30%|████████                   | 3/10 [04:43<12:49, 109.94s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 28. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 28. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3736445903778076, 'eval_runtime': 141.0628, 'eval_samples_per_second': 13.795, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
 40%|██████████▊                | 4/10 [07:04<12:14, 122.40s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 29. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 29. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3718647956848145, 'eval_runtime': 141.063, 'eval_samples_per_second': 13.795, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
 50%|█████████████▌             | 5/10 [09:26<10:46, 129.30s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 30. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 30. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.372274398803711, 'eval_runtime': 141.0725, 'eval_samples_per_second': 13.794, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
 60%|████████████████▏          | 6/10 [11:47<08:53, 133.45s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3728456497192383, 'eval_runtime': 141.0552, 'eval_samples_per_second': 13.796, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
 70%|██████████████████▉        | 7/10 [14:09<06:48, 136.08s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 32. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 32. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3732694387435913, 'eval_runtime': 141.0614, 'eval_samples_per_second': 13.795, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
 80%|█████████████████████▌     | 8/10 [16:30<04:35, 137.80s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 33. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 33. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3733704090118408, 'eval_runtime': 141.0535, 'eval_samples_per_second': 13.796, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
 90%|████████████████████████▎  | 9/10 [18:52<02:18, 138.95s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 34. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 34. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.373262643814087, 'eval_runtime': 141.0308, 'eval_samples_per_second': 13.798, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
100%|██████████████████████████| 10/10 [21:13<00:00, 139.72s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 35. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 35. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3736186027526855, 'eval_runtime': 141.0366, 'eval_samples_per_second': 13.798, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
{'loss': 0.2677, 'grad_norm': 1.8203125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|███████████████████████████████████████████████████| 10/10 [23:34<00:00, 139.72s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 37. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 37. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.373327612876892, 'eval_runtime': 141.0507, 'eval_samples_per_second': 13.796, 'eval_steps_per_second': 1.73, 'epoch': 0.0}
100%|███████████████████████████████████████████████████| 10/10 [23:50<00:00, 139.72s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 1430.6225, 'train_samples_per_second': 0.014, 'train_steps_per_second': 0.007, 'train_loss': 0.26766605377197267, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 38. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|███████████████████████████████████████████████████| 10/10 [24:16<00:00, 145.64s/it]

-------------------------
Student evaluation for 2: 1.3631418488911091, perplexity: 3.908453941345215, tokens: 1024012
Ensemble evaluation for 2: 1.3402463558106534, perplexity: 3.8199844360351562, tokens: 1024012
Teacher evaluation for 2: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 2 at: 2025-05-25 16:50:34
Completed in: 29m 10s
Total training time: 64m 36s
==================================================


==================================================
Starting Round 3 at: 2025-05-25 16:50:35
==================================================
Round '3' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_4/round_3
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 20%|██████████▍                                         | 2/10 [03:01<14:13, 106.64s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 1 that is less than the current step 40. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3705145120620728, 'eval_runtime': 180.4195, 'eval_samples_per_second': 10.786, 'eval_steps_per_second': 1.352, 'epoch': 0.0}
 30%|███████████████▌                                    | 3/10 [06:02<16:23, 140.57s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 41. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 2 that is less than the current step 41. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3729609251022339, 'eval_runtime': 180.3111, 'eval_samples_per_second': 10.792, 'eval_steps_per_second': 1.353, 'epoch': 0.0}
 40%|████████████████████▊                               | 4/10 [09:03<15:38, 156.40s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 42. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 3 that is less than the current step 42. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3740345239639282, 'eval_runtime': 180.1707, 'eval_samples_per_second': 10.801, 'eval_steps_per_second': 1.354, 'epoch': 0.0}
 50%|██████████████████████████                          | 5/10 [12:03<13:45, 165.10s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 43. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 4 that is less than the current step 43. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3751164674758911, 'eval_runtime': 180.0328, 'eval_samples_per_second': 10.809, 'eval_steps_per_second': 1.355, 'epoch': 0.0}
 60%|███████████████████████████████▏                    | 6/10 [15:04<11:21, 170.37s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 44. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 5 that is less than the current step 44. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
{'eval_loss': 1.3748635053634644, 'eval_runtime': 180.0768, 'eval_samples_per_second': 10.806, 'eval_steps_per_second': 1.355, 'epoch': 0.0}
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                               | 7/10 [18:04<08:41, 173.70s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 45. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 6 that is less than the current step 45. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         | 5/244 [00:02<02:35,  1.53it/s]        
{'eval_loss': 1.3749271631240845, 'eval_runtime': 180.066, 'eval_samples_per_second': 10.807, 'eval_steps_per_second': 1.355, 'epoch': 0.0}
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 8/10 [21:05<05:51, 175.89s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 46. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 7 that is less than the current step 46. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         | 4/244 [00:02<02:25,  1.65it/s]
{'eval_loss': 1.3749370574951172, 'eval_runtime': 180.0926, 'eval_samples_per_second': 10.806, 'eval_steps_per_second': 1.355, 'epoch': 0.0}
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 9/10 [24:05<02:57, 177.34s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 47. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 8 that is less than the current step 47. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         | 3/244 [00:01<02:05,  1.91it/s]
{'eval_loss': 1.3749399185180664, 'eval_runtime': 180.0359, 'eval_samples_per_second': 10.809, 'eval_steps_per_second': 1.355, 'epoch': 0.0}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [27:06<00:00, 178.39s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 48. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 9 that is less than the current step 48. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         | 2/244 [00:00<01:29,  2.71it/s]
{'eval_loss': 1.375169038772583, 'eval_runtime': 180.1013, 'eval_samples_per_second': 10.805, 'eval_steps_per_second': 1.355, 'epoch': 0.0}
{'loss': 0.2608, 'grad_norm': 1.59375, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 49. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [30:06<00:00, 178.39s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 50. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 50. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                                                        
{'eval_loss': 1.3751838207244873, 'eval_runtime': 179.9804, 'eval_samples_per_second': 10.812, 'eval_steps_per_second': 1.356, 'epoch': 0.0}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [30:24<00:00, 178.39s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 1824.3056, 'train_samples_per_second': 0.011, 'train_steps_per_second': 0.005, 'train_loss': 0.26077244281768797, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 51. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [30:58<00:00, 185.87s/it]

-------------------------
Student evaluation for 3: 1.3801055577725319, perplexity: 3.9753215312957764, tokens: 1024012
Ensemble evaluation for 3: 1.3417070019839348, perplexity: 3.825568199157715, tokens: 1024012
Teacher evaluation for 3: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 3 at: 2025-05-25 17:27:09
Completed in: 36m 33s
Total training time: 101m 11s
==================================================


==================================================
Training completed at: 2025-05-25 17:27:10
Total training time: 101m 12s
==================================================
