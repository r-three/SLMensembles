Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.

==================================================
Starting Round 0 at: 2025-05-25 18:51:21
==================================================
Round '0' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_1/round_0
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
[34m[1mwandb[0m: [33mWARNING[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:37<00:00, 50.91s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         
{'eval_loss': 1.430925726890564, 'eval_runtime': 50.703, 'eval_samples_per_second': 38.38, 'eval_steps_per_second': 4.812, 'epoch': 0.0}
{'eval_loss': 1.4008212089538574, 'eval_runtime': 50.9281, 'eval_samples_per_second': 38.211, 'eval_steps_per_second': 4.791, 'epoch': 0.0}
{'eval_loss': 1.3869866132736206, 'eval_runtime': 51.0805, 'eval_samples_per_second': 38.097, 'eval_steps_per_second': 4.777, 'epoch': 0.0}
{'eval_loss': 1.3833584785461426, 'eval_runtime': 51.1572, 'eval_samples_per_second': 38.04, 'eval_steps_per_second': 4.77, 'epoch': 0.0}
{'eval_loss': 1.3810641765594482, 'eval_runtime': 51.1432, 'eval_samples_per_second': 38.05, 'eval_steps_per_second': 4.771, 'epoch': 0.0}
{'eval_loss': 1.3805750608444214, 'eval_runtime': 51.1515, 'eval_samples_per_second': 38.044, 'eval_steps_per_second': 4.77, 'epoch': 0.0}
{'eval_loss': 1.3808621168136597, 'eval_runtime': 51.1496, 'eval_samples_per_second': 38.045, 'eval_steps_per_second': 4.77, 'epoch': 0.0}
{'eval_loss': 1.3805091381072998, 'eval_runtime': 51.1467, 'eval_samples_per_second': 38.047, 'eval_steps_per_second': 4.771, 'epoch': 0.0}
{'eval_loss': 1.379863977432251, 'eval_runtime': 51.1513, 'eval_samples_per_second': 38.044, 'eval_steps_per_second': 4.77, 'epoch': 0.0}
{'loss': 0.3384, 'grad_norm': 7.125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
{'eval_loss': 1.381075382232666, 'eval_runtime': 51.1402, 'eval_samples_per_second': 38.052, 'eval_steps_per_second': 4.771, 'epoch': 0.0}
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:53<00:00, 50.91s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 533.8477, 'train_samples_per_second': 0.037, 'train_steps_per_second': 0.019, 'train_loss': 0.33835787773132325, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 12. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [09:22<00:00, 56.26s/it]

-------------------------
Student evaluation for 0: 1.3470528147001501, perplexity: 3.846073627471924, tokens: 1024012
Ensemble evaluation for 0: 1.3470528147001501, perplexity: 3.846073627471924, tokens: 1024012
Teacher evaluation for 0: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 0 at: 2025-05-25 19:04:20
Completed in: 12m 59s
Total training time: 13m 40s
==================================================


==================================================
Starting Round 1 at: 2025-05-25 19:04:21
==================================================
Round '1' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_1/round_1
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 20%|███████████████████████████████████████████████                                                                                                                                                                                            | 2/10 [01:42<08:01, 60.15s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11 that is less than the current step 14. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11 that is less than the current step 14. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 15/244 [00:05<01:35,  2.40it/s]
{'eval_loss': 1.3773891925811768, 'eval_runtime': 101.4783, 'eval_samples_per_second': 19.177, 'eval_steps_per_second': 2.404, 'epoch': 0.0}
 30%|██████████████████████████████████████████████████████████████████████▌                                                                                                                                                                    | 3/10 [03:24<09:14, 79.22s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12 that is less than the current step 15. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12 that is less than the current step 15. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 11/244 [00:04<01:35,  2.43it/s]
{'eval_loss': 1.372111439704895, 'eval_runtime': 101.5128, 'eval_samples_per_second': 19.17, 'eval_steps_per_second': 2.404, 'epoch': 0.0}
 40%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 4/10 [05:06<08:48, 88.15s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 6/244 [00:02<01:31,  2.61it/s]
{'eval_loss': 1.3738526105880737, 'eval_runtime': 101.4272, 'eval_samples_per_second': 19.186, 'eval_steps_per_second': 2.406, 'epoch': 0.0}
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                     | 5/10 [06:47<07:45, 93.07s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14 that is less than the current step 17. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14 that is less than the current step 17. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 2/244 [00:00<00:50,  4.82it/s]
{'eval_loss': 1.37360417842865, 'eval_runtime': 101.3988, 'eval_samples_per_second': 19.192, 'eval_steps_per_second': 2.406, 'epoch': 0.0}
 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                              | 6/10 [08:29<06:24, 96.10s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15 that is less than the current step 18. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15 that is less than the current step 18. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 21/244 [00:08<01:32,  2.40it/s]
{'eval_loss': 1.3739148378372192, 'eval_runtime': 101.5713, 'eval_samples_per_second': 19.159, 'eval_steps_per_second': 2.402, 'epoch': 0.0}
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 7/10 [10:11<04:53, 97.94s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 17/244 [00:06<01:34,  2.40it/s]
{'eval_loss': 1.374362587928772, 'eval_runtime': 101.3442, 'eval_samples_per_second': 19.202, 'eval_steps_per_second': 2.408, 'epoch': 0.0}
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 8/10 [11:53<03:18, 99.18s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 13/244 [00:04<01:35,  2.42it/s]
{'eval_loss': 1.374890923500061, 'eval_runtime': 101.4296, 'eval_samples_per_second': 19.186, 'eval_steps_per_second': 2.406, 'epoch': 0.0}
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 9/10 [13:35<01:40, 100.01s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 8/244 [00:02<01:34,  2.49it/s]
{'eval_loss': 1.3745217323303223, 'eval_runtime': 101.4255, 'eval_samples_per_second': 19.187, 'eval_steps_per_second': 2.406, 'epoch': 0.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [15:17<00:00, 100.57s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 4/244 [00:01<01:21,  2.94it/s]
{'eval_loss': 1.3746449947357178, 'eval_runtime': 101.4448, 'eval_samples_per_second': 19.183, 'eval_steps_per_second': 2.405, 'epoch': 0.0}
{'loss': 0.3464, 'grad_norm': 3.234375, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 23. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [16:58<00:00, 100.57s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         
{'eval_loss': 1.3746367692947388, 'eval_runtime': 101.1872, 'eval_samples_per_second': 19.232, 'eval_steps_per_second': 2.411, 'epoch': 0.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [17:13<00:00, 100.57s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 1033.9979, 'train_samples_per_second': 0.019, 'train_steps_per_second': 0.01, 'train_loss': 0.34640016555786135, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 25. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [17:46<00:00, 106.65s/it]

-------------------------
Student evaluation for 1: 1.3450480046601818, perplexity: 3.8383705615997314, tokens: 1024012
Ensemble evaluation for 1: 1.3415322102129028, perplexity: 3.824899673461914, tokens: 1024012
Teacher evaluation for 1: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 1 at: 2025-05-25 19:26:23
Completed in: 22m 2s
Total training time: 35m 43s
==================================================


==================================================
Starting Round 2 at: 2025-05-25 19:26:23
==================================================
Round '2' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_1/round_2
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 20%|███████████████████████████████████████████████                                                                                                                                                                                            | 2/10 [02:21<11:06, 83.28s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21 that is less than the current step 27. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 21 that is less than the current step 27. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 16/244 [00:08<02:11,  1.73it/s]
{'eval_loss': 1.3769720792770386, 'eval_runtime': 140.7914, 'eval_samples_per_second': 13.822, 'eval_steps_per_second': 1.733, 'epoch': 0.0}
 30%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                                   | 3/10 [04:43<12:48, 109.77s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22 that is less than the current step 28. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 22 that is less than the current step 28. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 14/244 [00:07<02:12,  1.73it/s]
{'eval_loss': 1.3739081621170044, 'eval_runtime': 140.7427, 'eval_samples_per_second': 13.827, 'eval_steps_per_second': 1.734, 'epoch': 0.0}
 40%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 4/10 [07:04<12:13, 122.24s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23 that is less than the current step 29. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 23 that is less than the current step 29. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 11/244 [00:05<02:13,  1.75it/s]
{'eval_loss': 1.3722126483917236, 'eval_runtime': 140.7935, 'eval_samples_per_second': 13.822, 'eval_steps_per_second': 1.733, 'epoch': 0.0}
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                     | 5/10 [09:25<10:45, 129.12s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24 that is less than the current step 30. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 24 that is less than the current step 30. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 9/244 [00:04<02:12,  1.77it/s]
{'eval_loss': 1.3724600076675415, 'eval_runtime': 140.7743, 'eval_samples_per_second': 13.824, 'eval_steps_per_second': 1.733, 'epoch': 0.0}
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 6/10 [11:46<08:53, 133.26s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 25 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 7/244 [00:03<02:09,  1.83it/s]
{'eval_loss': 1.3726956844329834, 'eval_runtime': 140.8228, 'eval_samples_per_second': 13.819, 'eval_steps_per_second': 1.733, 'epoch': 0.0}
 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 7/10 [14:08<06:47, 135.86s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26 that is less than the current step 32. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 26 that is less than the current step 32. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 5/244 [00:02<02:01,  1.97it/s]
{'eval_loss': 1.3733675479888916, 'eval_runtime': 140.7791, 'eval_samples_per_second': 13.823, 'eval_steps_per_second': 1.733, 'epoch': 0.0}
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 8/10 [16:29<04:35, 137.55s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27 that is less than the current step 33. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 27 that is less than the current step 33. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.         | 3/244 [00:01<01:38,  2.45it/s]
{'eval_loss': 1.3739482164382935, 'eval_runtime': 140.7271, 'eval_samples_per_second': 13.828, 'eval_steps_per_second': 1.734, 'epoch': 0.0}
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 9/10 [18:50<02:18, 138.68s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28 that is less than the current step 34. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 28 that is less than the current step 34. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                 | 0/244 [00:00<?, ?it/s]
{'eval_loss': 1.3738638162612915, 'eval_runtime': 140.7286, 'eval_samples_per_second': 13.828, 'eval_steps_per_second': 1.734, 'epoch': 0.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [21:11<00:00, 139.44s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29 that is less than the current step 35. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 29 that is less than the current step 35. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.        | 16/244 [00:08<02:11,  1.73it/s]
{'eval_loss': 1.3739194869995117, 'eval_runtime': 140.7177, 'eval_samples_per_second': 13.829, 'eval_steps_per_second': 1.734, 'epoch': 0.0}
{'loss': 0.2677, 'grad_norm': 1.8359375, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [23:32<00:00, 139.44s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30 that is less than the current step 37. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30 that is less than the current step 37. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                         
{'eval_loss': 1.3738534450531006, 'eval_runtime': 140.6893, 'eval_samples_per_second': 13.832, 'eval_steps_per_second': 1.734, 'epoch': 0.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [23:48<00:00, 139.44s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 1428.3247, 'train_samples_per_second': 0.014, 'train_steps_per_second': 0.007, 'train_loss': 0.2677262306213379, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 30 that is less than the current step 38. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [24:19<00:00, 145.94s/it]

-------------------------
Student evaluation for 2: 1.3641885759485395, perplexity: 3.9125468730926514, tokens: 1024012
Ensemble evaluation for 2: 1.3402288120657186, perplexity: 3.8199174404144287, tokens: 1024012
Teacher evaluation for 2: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 2 at: 2025-05-25 19:55:37
Completed in: 29m 13s
Total training time: 64m 57s
==================================================


==================================================
Starting Round 3 at: 2025-05-25 19:55:38
==================================================
Round '3' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_1/round_3
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 10%|███████████████████████▌                                                                                                                                                                                                                   | 1/10 [00:00<00:04,  1.93it/s]Traceback (most recent call last):
  File "/h/klambert/slm_ensembles/train.py", line 329, in <module>                                                                                                                                                                             | 4/244 [00:02<02:24,  1.66it/s]
    main()
  File "/h/klambert/slm_ensembles/train.py", line 257, in main
    trainer.train()
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2627, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3096, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3045, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 4154, in evaluate
    output = eval_loop(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 4348, in evaluation_loop
    losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/h/klambert/slm_ensembles/train.py", line 133, in prediction_step
    student_logits = model(input_ids=input_ids, attention_mask=attention_mask).logits
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
    layer_outputs = decoder_layer(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 262, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 169, in forward
    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 93, in apply_rotary_pos_emb
    k_embed = (k * cos) + (rotate_half(k) * sin)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 67, in rotate_half
    return torch.cat((-x2, x1), dim=-1)
KeyboardInterrupt
