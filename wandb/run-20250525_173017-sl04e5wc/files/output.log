Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.

==================================================
Starting Round 0 at: 2025-05-25 17:30:22
==================================================
Round '0' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_5/round_0
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
[34m[1mwandb[0m: [33mWARNING[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:36<00:00, 50.98s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 11. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                                                        
{'eval_loss': 1.430925726890564, 'eval_runtime': 50.8048, 'eval_samples_per_second': 38.304, 'eval_steps_per_second': 4.803, 'epoch': 0.0}
{'eval_loss': 1.4008212089538574, 'eval_runtime': 51.0879, 'eval_samples_per_second': 38.091, 'eval_steps_per_second': 4.776, 'epoch': 0.0}
{'eval_loss': 1.3869866132736206, 'eval_runtime': 51.2231, 'eval_samples_per_second': 37.991, 'eval_steps_per_second': 4.763, 'epoch': 0.0}
{'eval_loss': 1.3833584785461426, 'eval_runtime': 51.2748, 'eval_samples_per_second': 37.952, 'eval_steps_per_second': 4.759, 'epoch': 0.0}
{'eval_loss': 1.3807860612869263, 'eval_runtime': 51.2741, 'eval_samples_per_second': 37.953, 'eval_steps_per_second': 4.759, 'epoch': 0.0}
{'eval_loss': 1.380422830581665, 'eval_runtime': 51.2795, 'eval_samples_per_second': 37.949, 'eval_steps_per_second': 4.758, 'epoch': 0.0}
{'eval_loss': 1.380132794380188, 'eval_runtime': 51.3082, 'eval_samples_per_second': 37.928, 'eval_steps_per_second': 4.756, 'epoch': 0.0}
{'eval_loss': 1.3794302940368652, 'eval_runtime': 51.2871, 'eval_samples_per_second': 37.943, 'eval_steps_per_second': 4.758, 'epoch': 0.0}
{'eval_loss': 1.3796895742416382, 'eval_runtime': 51.2997, 'eval_samples_per_second': 37.934, 'eval_steps_per_second': 4.756, 'epoch': 0.0}
{'loss': 0.3382, 'grad_norm': 7.1875, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
{'eval_loss': 1.3800921440124512, 'eval_runtime': 51.2696, 'eval_samples_per_second': 37.956, 'eval_steps_per_second': 4.759, 'epoch': 0.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [08:51<00:00, 50.98s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 531.4639, 'train_samples_per_second': 0.038, 'train_steps_per_second': 0.019, 'train_loss': 0.3382404804229736, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 10 that is less than the current step 12. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [09:24<00:00, 56.42s/it]

-------------------------
Student evaluation for 0: 1.3461227197684007, perplexity: 3.842498302459717, tokens: 1024012
Ensemble evaluation for 0: 1.3461227197684007, perplexity: 3.842498302459717, tokens: 1024012
Teacher evaluation for 0: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 0 at: 2025-05-25 17:43:22
Completed in: 13m 0s
Total training time: 13m 5s
==================================================


==================================================
Starting Round 1 at: 2025-05-25 17:43:23
==================================================
Round '1' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_5/round_1
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
 10%|██████████████████████████▌                                                                                                                                                                                                                                               | 1/10 [01:42<00:04,  2.03it/s][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11 that is less than the current step 14. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 11 that is less than the current step 14. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                                                        
{'eval_loss': 1.3765212297439575, 'eval_runtime': 101.5508, 'eval_samples_per_second': 19.163, 'eval_steps_per_second': 2.403, 'epoch': 0.0}
 30%|███████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                          | 3/10 [03:24<09:14, 79.28s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12 that is less than the current step 15. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 12 that is less than the current step 15. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                       | 19/244 [00:07<01:33,  2.40it/s]
{'eval_loss': 1.3715333938598633, 'eval_runtime': 101.6036, 'eval_samples_per_second': 19.153, 'eval_steps_per_second': 2.401, 'epoch': 0.0}
 40%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                               | 4/10 [05:06<08:49, 88.22s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 13 that is less than the current step 16. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                       | 14/244 [00:05<01:35,  2.41it/s]
{'eval_loss': 1.3726898431777954, 'eval_runtime': 101.5202, 'eval_samples_per_second': 19.169, 'eval_steps_per_second': 2.403, 'epoch': 0.0}
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 5/10 [06:48<07:45, 93.16s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14 that is less than the current step 17. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 14 that is less than the current step 17. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                       | 10/244 [00:03<01:35,  2.44it/s]
{'eval_loss': 1.3730297088623047, 'eval_runtime': 101.5177, 'eval_samples_per_second': 19.169, 'eval_steps_per_second': 2.404, 'epoch': 0.0}
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                          | 6/10 [08:30<06:24, 96.13s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15 that is less than the current step 18. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 15 that is less than the current step 18. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                        | 5/244 [00:01<01:27,  2.73it/s]
{'eval_loss': 1.3732852935791016, 'eval_runtime': 101.4947, 'eval_samples_per_second': 19.173, 'eval_steps_per_second': 2.404, 'epoch': 0.0}
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 7/10 [10:12<04:54, 98.04s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 16 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                                                        
{'eval_loss': 1.373856544494629, 'eval_runtime': 101.4895, 'eval_samples_per_second': 19.174, 'eval_steps_per_second': 2.404, 'epoch': 0.0}
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 8/10 [11:53<03:18, 99.24s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 17 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                       | 20/244 [00:07<01:33,  2.40it/s]
{'eval_loss': 1.3741865158081055, 'eval_runtime': 101.3985, 'eval_samples_per_second': 19.192, 'eval_steps_per_second': 2.406, 'epoch': 0.0}
 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 9/10 [13:35<01:40, 100.04s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 18 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                       | 16/244 [00:06<01:34,  2.41it/s]
{'eval_loss': 1.374045491218567, 'eval_runtime': 101.3833, 'eval_samples_per_second': 19.194, 'eval_steps_per_second': 2.407, 'epoch': 0.0}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [15:17<00:00, 100.57s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 19 that is less than the current step 22. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                       | 11/244 [00:04<01:35,  2.43it/s]
{'eval_loss': 1.374096155166626, 'eval_runtime': 101.3426, 'eval_samples_per_second': 19.202, 'eval_steps_per_second': 2.408, 'epoch': 0.0}
{'loss': 0.346, 'grad_norm': 3.203125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 23. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [16:58<00:00, 100.57s/it][34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.                                                                        
{'eval_loss': 1.3737518787384033, 'eval_runtime': 101.3626, 'eval_samples_per_second': 19.198, 'eval_steps_per_second': 2.407, 'epoch': 0.0}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [17:14<00:00, 100.57s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 1034.5309, 'train_samples_per_second': 0.019, 'train_steps_per_second': 0.01, 'train_loss': 0.3460085868835449, 'epoch': 0.0}
[34m[1mwandb[0m: [33mWARNING[0m Tried to log to step 20 that is less than the current step 25. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [17:46<00:00, 106.69s/it]

-------------------------
Student evaluation for 1: 1.3444989067787625, perplexity: 3.836263656616211, tokens: 1024012
Ensemble evaluation for 1: 1.3404316171468067, perplexity: 3.8206920623779297, tokens: 1024012
Teacher evaluation for 1: 1.259693487730119, perplexity: 3.524341106414795, tokens: 1024012
-------------------------
==================================================
Ending Round 1 at: 2025-05-25 18:05:26
Completed in: 22m 2s
Total training time: 35m 9s
==================================================


==================================================
Starting Round 2 at: 2025-05-25 18:05:27
==================================================
Round '2' model stored in: /scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_5/round_2
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Traceback (most recent call last):
  File "/h/klambert/slm_ensembles/train.py", line 326, in <module>
    main()
  File "/h/klambert/slm_ensembles/train.py", line 245, in main
    trainer = DistillationTrainer(
  File "/h/klambert/slm_ensembles/train.py", line 92, in __init__
    super().__init__(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 358, in __init__
    super().__init__(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 692, in __init__
    os.makedirs(self.args.output_dir, exist_ok=True)
  File "/pkgs/python-3.10.12/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/scratch/ssd004/scratch/klambert/slm_ensembles/boosted_distillation_1.5B_teacher_average_fixed_logging/2025-05-25/run_5/round_2'
