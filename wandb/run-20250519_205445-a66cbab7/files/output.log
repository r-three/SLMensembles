Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Teacher model evaluation: {'eval_loss': 1.3539468194424984}
No prior ensemble loaded

==================================================
Starting Round 0 at: 2025-05-19 20:57:07
==================================================
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: WARNING The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
  0%|          | 0/1000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
                                                    
{'loss': 3.81, 'grad_norm': 119.5, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.0}
{'loss': 2.9426, 'grad_norm': 41.75, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.0}
{'loss': 2.4494, 'grad_norm': 42.25, 'learning_rate': 1.16e-05, 'epoch': 0.0}
{'loss': 2.337, 'grad_norm': 29.75, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.0}
{'loss': 2.1872, 'grad_norm': 21.75, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.0}
{'loss': 2.2354, 'grad_norm': 29.625, 'learning_rate': 1.9810526315789476e-05, 'epoch': 0.0}
{'loss': 2.1513, 'grad_norm': 38.5, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.01}
{'loss': 1.9679, 'grad_norm': 31.5, 'learning_rate': 1.9389473684210525e-05, 'epoch': 0.01}
{'loss': 2.3877, 'grad_norm': 21.25, 'learning_rate': 1.9178947368421055e-05, 'epoch': 0.01}
{'loss': 2.2124, 'grad_norm': 20.375, 'learning_rate': 1.8968421052631582e-05, 'epoch': 0.01}
                                                 
{'eval_loss': 1.3906519412994385, 'eval_runtime': 58.7325, 'eval_samples_per_second': 33.133, 'eval_steps_per_second': 4.154, 'epoch': 0.01}
{'loss': 1.8841, 'grad_norm': 22.5, 'learning_rate': 1.8757894736842105e-05, 'epoch': 0.01}
{'loss': 1.922, 'grad_norm': 20.375, 'learning_rate': 1.8547368421052635e-05, 'epoch': 0.01}
{'loss': 2.0951, 'grad_norm': 39.75, 'learning_rate': 1.8336842105263158e-05, 'epoch': 0.01}
{'loss': 2.3106, 'grad_norm': 25.375, 'learning_rate': 1.8126315789473685e-05, 'epoch': 0.01}
{'loss': 2.1084, 'grad_norm': 12.5, 'learning_rate': 1.7915789473684214e-05, 'epoch': 0.01}
{'loss': 2.4528, 'grad_norm': 17.125, 'learning_rate': 1.7705263157894738e-05, 'epoch': 0.01}
{'loss': 1.9213, 'grad_norm': 18.5, 'learning_rate': 1.7494736842105264e-05, 'epoch': 0.01}
{'loss': 2.0686, 'grad_norm': 16.25, 'learning_rate': 1.728421052631579e-05, 'epoch': 0.01}
{'loss': 1.9779, 'grad_norm': 16.625, 'learning_rate': 1.7073684210526317e-05, 'epoch': 0.02}
{'loss': 2.0514, 'grad_norm': 15.1875, 'learning_rate': 1.6863157894736844e-05, 'epoch': 0.02}
{'eval_loss': 1.3858070373535156, 'eval_runtime': 58.6567, 'eval_samples_per_second': 33.176, 'eval_steps_per_second': 4.16, 'epoch': 0.02}
{'loss': 1.9929, 'grad_norm': 14.4375, 'learning_rate': 1.665263157894737e-05, 'epoch': 0.02}
{'loss': 2.2682, 'grad_norm': 20.25, 'learning_rate': 1.6442105263157897e-05, 'epoch': 0.02}
{'loss': 1.9134, 'grad_norm': 18.625, 'learning_rate': 1.6231578947368423e-05, 'epoch': 0.02}
{'loss': 1.9404, 'grad_norm': 23.625, 'learning_rate': 1.6021052631578947e-05, 'epoch': 0.02}
{'loss': 2.255, 'grad_norm': 21.625, 'learning_rate': 1.5810526315789473e-05, 'epoch': 0.02}
{'loss': 1.969, 'grad_norm': 28.625, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.02}
{'loss': 2.2551, 'grad_norm': 21.625, 'learning_rate': 1.5389473684210526e-05, 'epoch': 0.02}
{'loss': 1.9984, 'grad_norm': 22.25, 'learning_rate': 1.5178947368421053e-05, 'epoch': 0.02}
{'loss': 2.0537, 'grad_norm': 18.75, 'learning_rate': 1.4968421052631581e-05, 'epoch': 0.02}
{'loss': 2.0078, 'grad_norm': 24.5, 'learning_rate': 1.4757894736842106e-05, 'epoch': 0.02}
{'eval_loss': 1.3864400386810303, 'eval_runtime': 58.7009, 'eval_samples_per_second': 33.151, 'eval_steps_per_second': 4.157, 'epoch': 0.02}
{'loss': 2.0238, 'grad_norm': 17.625, 'learning_rate': 1.4547368421052632e-05, 'epoch': 0.03}
{'loss': 1.9787, 'grad_norm': 17.75, 'learning_rate': 1.433684210526316e-05, 'epoch': 0.03}
{'loss': 1.9155, 'grad_norm': 16.25, 'learning_rate': 1.4126315789473686e-05, 'epoch': 0.03}
{'loss': 1.8103, 'grad_norm': 15.8125, 'learning_rate': 1.3915789473684212e-05, 'epoch': 0.03}
{'loss': 1.9932, 'grad_norm': 22.375, 'learning_rate': 1.3705263157894737e-05, 'epoch': 0.03}
{'loss': 2.0776, 'grad_norm': 17.375, 'learning_rate': 1.3494736842105265e-05, 'epoch': 0.03}
{'loss': 1.9574, 'grad_norm': 20.125, 'learning_rate': 1.328421052631579e-05, 'epoch': 0.03}
{'loss': 2.106, 'grad_norm': 16.0, 'learning_rate': 1.3073684210526317e-05, 'epoch': 0.03}
{'loss': 2.13, 'grad_norm': 20.625, 'learning_rate': 1.2863157894736845e-05, 'epoch': 0.03}
{'loss': 2.2005, 'grad_norm': 21.25, 'learning_rate': 1.265263157894737e-05, 'epoch': 0.03}
{'eval_loss': 1.3881069421768188, 'eval_runtime': 58.6498, 'eval_samples_per_second': 33.18, 'eval_steps_per_second': 4.16, 'epoch': 0.03}
{'loss': 2.1156, 'grad_norm': 27.375, 'learning_rate': 1.2442105263157895e-05, 'epoch': 0.03}
{'loss': 2.1235, 'grad_norm': 14.0, 'learning_rate': 1.2231578947368421e-05, 'epoch': 0.03}
{'loss': 1.8928, 'grad_norm': 15.0, 'learning_rate': 1.202105263157895e-05, 'epoch': 0.04}
{'loss': 2.1369, 'grad_norm': 19.875, 'learning_rate': 1.1810526315789474e-05, 'epoch': 0.04}
{'loss': 1.9249, 'grad_norm': 16.25, 'learning_rate': 1.16e-05, 'epoch': 0.04}
{'loss': 1.8196, 'grad_norm': 14.5, 'learning_rate': 1.1389473684210527e-05, 'epoch': 0.04}
{'loss': 2.1471, 'grad_norm': 23.875, 'learning_rate': 1.1178947368421054e-05, 'epoch': 0.04}
{'loss': 2.011, 'grad_norm': 15.5625, 'learning_rate': 1.0968421052631579e-05, 'epoch': 0.04}
{'loss': 1.9448, 'grad_norm': 25.375, 'learning_rate': 1.0757894736842107e-05, 'epoch': 0.04}
{'loss': 1.9336, 'grad_norm': 20.5, 'learning_rate': 1.0547368421052633e-05, 'epoch': 0.04}
{'eval_loss': 1.3893697261810303, 'eval_runtime': 58.6466, 'eval_samples_per_second': 33.182, 'eval_steps_per_second': 4.161, 'epoch': 0.04}
{'loss': 2.0756, 'grad_norm': 15.8125, 'learning_rate': 1.0336842105263158e-05, 'epoch': 0.04}
{'loss': 1.9987, 'grad_norm': 14.625, 'learning_rate': 1.0126315789473685e-05, 'epoch': 0.04}
{'loss': 2.043, 'grad_norm': 17.75, 'learning_rate': 9.915789473684211e-06, 'epoch': 0.04}
{'loss': 1.955, 'grad_norm': 15.25, 'learning_rate': 9.705263157894738e-06, 'epoch': 0.04}
{'loss': 2.0375, 'grad_norm': 18.875, 'learning_rate': 9.494736842105265e-06, 'epoch': 0.05}
{'loss': 1.9501, 'grad_norm': 21.5, 'learning_rate': 9.28421052631579e-06, 'epoch': 0.05}
{'loss': 2.0666, 'grad_norm': 19.75, 'learning_rate': 9.073684210526316e-06, 'epoch': 0.05}
{'loss': 2.0436, 'grad_norm': 21.625, 'learning_rate': 8.863157894736842e-06, 'epoch': 0.05}
{'loss': 1.8326, 'grad_norm': 31.875, 'learning_rate': 8.652631578947369e-06, 'epoch': 0.05}
{'loss': 2.0297, 'grad_norm': 23.5, 'learning_rate': 8.442105263157896e-06, 'epoch': 0.05}
{'eval_loss': 1.385830044746399, 'eval_runtime': 58.7272, 'eval_samples_per_second': 33.136, 'eval_steps_per_second': 4.155, 'epoch': 0.05}
{'loss': 1.9889, 'grad_norm': 13.6875, 'learning_rate': 8.231578947368422e-06, 'epoch': 0.05}
{'loss': 2.1589, 'grad_norm': 19.875, 'learning_rate': 8.021052631578949e-06, 'epoch': 0.05}
{'loss': 1.8472, 'grad_norm': 22.375, 'learning_rate': 7.810526315789474e-06, 'epoch': 0.05}
{'loss': 2.0292, 'grad_norm': 16.875, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.05}
{'loss': 2.0328, 'grad_norm': 12.5625, 'learning_rate': 7.3894736842105275e-06, 'epoch': 0.05}
{'loss': 1.8441, 'grad_norm': 18.5, 'learning_rate': 7.178947368421053e-06, 'epoch': 0.05}
{'loss': 1.9461, 'grad_norm': 12.3125, 'learning_rate': 6.96842105263158e-06, 'epoch': 0.06}
{'loss': 1.8569, 'grad_norm': 16.875, 'learning_rate': 6.7578947368421054e-06, 'epoch': 0.06}
{'loss': 1.8938, 'grad_norm': 31.0, 'learning_rate': 6.547368421052632e-06, 'epoch': 0.06}
{'loss': 2.0289, 'grad_norm': 13.9375, 'learning_rate': 6.336842105263158e-06, 'epoch': 0.06}
{'eval_loss': 1.385064959526062, 'eval_runtime': 58.7388, 'eval_samples_per_second': 33.13, 'eval_steps_per_second': 4.154, 'epoch': 0.06}
{'loss': 2.1032, 'grad_norm': 18.875, 'learning_rate': 6.126315789473685e-06, 'epoch': 0.06}
{'loss': 2.0088, 'grad_norm': 17.375, 'learning_rate': 5.915789473684212e-06, 'epoch': 0.06}
{'loss': 1.9479, 'grad_norm': 15.9375, 'learning_rate': 5.705263157894737e-06, 'epoch': 0.06}
{'loss': 2.1005, 'grad_norm': 25.0, 'learning_rate': 5.494736842105264e-06, 'epoch': 0.06}
{'loss': 1.8996, 'grad_norm': 15.375, 'learning_rate': 5.2842105263157896e-06, 'epoch': 0.06}
{'loss': 1.923, 'grad_norm': 19.625, 'learning_rate': 5.073684210526316e-06, 'epoch': 0.06}
{'loss': 1.8238, 'grad_norm': 15.125, 'learning_rate': 4.863157894736843e-06, 'epoch': 0.06}
{'loss': 1.895, 'grad_norm': 13.0, 'learning_rate': 4.652631578947368e-06, 'epoch': 0.06}
{'loss': 1.9549, 'grad_norm': 18.625, 'learning_rate': 4.442105263157896e-06, 'epoch': 0.07}
{'loss': 1.9103, 'grad_norm': 21.0, 'learning_rate': 4.2315789473684215e-06, 'epoch': 0.07}
{'eval_loss': 1.386731505393982, 'eval_runtime': 58.743, 'eval_samples_per_second': 33.127, 'eval_steps_per_second': 4.154, 'epoch': 0.07}
{'loss': 1.9376, 'grad_norm': 21.375, 'learning_rate': 4.021052631578948e-06, 'epoch': 0.07}
{'loss': 2.0921, 'grad_norm': 15.0625, 'learning_rate': 3.810526315789474e-06, 'epoch': 0.07}
{'loss': 2.1399, 'grad_norm': 14.1875, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.07}
{'loss': 1.8242, 'grad_norm': 12.8125, 'learning_rate': 3.3894736842105264e-06, 'epoch': 0.07}
{'loss': 1.8222, 'grad_norm': 16.875, 'learning_rate': 3.178947368421053e-06, 'epoch': 0.07}
{'loss': 1.8468, 'grad_norm': 17.75, 'learning_rate': 2.9684210526315795e-06, 'epoch': 0.07}
{'loss': 1.9003, 'grad_norm': 24.25, 'learning_rate': 2.7578947368421056e-06, 'epoch': 0.07}
{'loss': 1.933, 'grad_norm': 25.125, 'learning_rate': 2.5473684210526317e-06, 'epoch': 0.07}
{'loss': 1.991, 'grad_norm': 34.0, 'learning_rate': 2.3368421052631583e-06, 'epoch': 0.07}
{'loss': 1.8944, 'grad_norm': 22.625, 'learning_rate': 2.1263157894736844e-06, 'epoch': 0.07}
{'eval_loss': 1.3874702453613281, 'eval_runtime': 58.7029, 'eval_samples_per_second': 33.15, 'eval_steps_per_second': 4.157, 'epoch': 0.07}
{'loss': 2.193, 'grad_norm': 19.125, 'learning_rate': 1.9157894736842105e-06, 'epoch': 0.08}
{'loss': 2.0726, 'grad_norm': 27.875, 'learning_rate': 1.705263157894737e-06, 'epoch': 0.08}
{'loss': 2.0183, 'grad_norm': 23.75, 'learning_rate': 1.4947368421052632e-06, 'epoch': 0.08}
{'loss': 1.9036, 'grad_norm': 13.625, 'learning_rate': 1.2842105263157895e-06, 'epoch': 0.08}
{'loss': 1.9195, 'grad_norm': 17.375, 'learning_rate': 1.0736842105263159e-06, 'epoch': 0.08}
{'loss': 2.1423, 'grad_norm': 20.75, 'learning_rate': 8.631578947368421e-07, 'epoch': 0.08}
{'loss': 2.1274, 'grad_norm': 25.5, 'learning_rate': 6.526315789473684e-07, 'epoch': 0.08}
{'loss': 2.0402, 'grad_norm': 12.6875, 'learning_rate': 4.421052631578947e-07, 'epoch': 0.08}
{'loss': 1.946, 'grad_norm': 21.5, 'learning_rate': 2.315789473684211e-07, 'epoch': 0.08}
{'loss': 1.9589, 'grad_norm': 18.75, 'learning_rate': 2.1052631578947368e-08, 'epoch': 0.08}
{'eval_loss': 1.386976718902588, 'eval_runtime': 58.706, 'eval_samples_per_second': 33.148, 'eval_steps_per_second': 4.156, 'epoch': 0.08}
{'train_runtime': 3696.0034, 'train_samples_per_second': 4.329, 'train_steps_per_second': 0.271, 'train_loss': 2.0529958782196043, 'epoch': 0.08}
Round 0 student evaluation: {'eval_loss': 1.4400636539077367}
Ensemble evaluation after round 0: {'eval_loss': 1.4400636539077367}
Round 0 completed in: 64m 34s
Total training time so far: 66m 57s

==================================================
Starting Round 1 at: 2025-05-19 22:01:44
==================================================
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.
  0%|          | 0/1000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/h/klambert/slm_ensembles/train.py", line 462, in <module>
    main()
  File "/h/klambert/slm_ensembles/train.py", line 331, in main
    trainer.train()
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/h/klambert/slm_ensembles/train.py", line 119, in compute_loss
    student_logits = model(**student_inputs).logits
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 818, in forward
    return model_forward(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 806, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 519, in forward
    causal_mask = self._update_causal_mask(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 613, in _update_causal_mask
    if AttentionMaskConverter._ignore_causal_mask_sdpa(
  File "/scratch/ssd004/scratch/klambert/slm_ensembles/venv/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py", line 288, in _ignore_causal_mask_sdpa
    elif not is_tracing and torch.all(attention_mask == 1):
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
