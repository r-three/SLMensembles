Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: WARNING The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
  0%|          | 0/1000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
                                                    
{'loss': 1.953, 'grad_norm': 33.75, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.0}
{'loss': 2.186, 'grad_norm': 113.0, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.0}
{'loss': 2.0986, 'grad_norm': 42.75, 'learning_rate': 1.16e-05, 'epoch': 0.0}
{'loss': 2.0862, 'grad_norm': 21.625, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.0}
{'loss': 1.9125, 'grad_norm': 63.0, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.0}
{'loss': 1.9449, 'grad_norm': 19.5, 'learning_rate': 1.9810526315789476e-05, 'epoch': 0.0}
{'loss': 1.868, 'grad_norm': 22.5, 'learning_rate': 1.9600000000000002e-05, 'epoch': 0.01}
{'loss': 1.8718, 'grad_norm': 29.375, 'learning_rate': 1.9389473684210525e-05, 'epoch': 0.01}
{'loss': 2.034, 'grad_norm': 27.25, 'learning_rate': 1.9178947368421055e-05, 'epoch': 0.01}
{'loss': 1.8294, 'grad_norm': 37.25, 'learning_rate': 1.8968421052631582e-05, 'epoch': 0.01}
                                                 
{'eval_loss': 0.9278299808502197, 'eval_runtime': 61.2101, 'eval_samples_per_second': 32.005, 'eval_steps_per_second': 4.003, 'epoch': 0.01}
{'loss': 2.0277, 'grad_norm': 25.875, 'learning_rate': 1.8757894736842105e-05, 'epoch': 0.01}
{'loss': 1.9259, 'grad_norm': 28.5, 'learning_rate': 1.8547368421052635e-05, 'epoch': 0.01}
{'loss': 1.6076, 'grad_norm': 18.0, 'learning_rate': 1.8336842105263158e-05, 'epoch': 0.01}
{'loss': 1.9242, 'grad_norm': 19.75, 'learning_rate': 1.8126315789473685e-05, 'epoch': 0.01}
{'loss': 2.305, 'grad_norm': 30.75, 'learning_rate': 1.7915789473684214e-05, 'epoch': 0.01}
{'loss': 1.9786, 'grad_norm': 18.5, 'learning_rate': 1.7705263157894738e-05, 'epoch': 0.01}
{'loss': 2.0185, 'grad_norm': 56.75, 'learning_rate': 1.7494736842105264e-05, 'epoch': 0.01}
{'loss': 1.8122, 'grad_norm': 37.5, 'learning_rate': 1.728421052631579e-05, 'epoch': 0.01}
{'loss': 1.7031, 'grad_norm': 22.875, 'learning_rate': 1.7073684210526317e-05, 'epoch': 0.02}
{'loss': 1.7396, 'grad_norm': 43.75, 'learning_rate': 1.6863157894736844e-05, 'epoch': 0.02}
{'eval_loss': 0.9279585480690002, 'eval_runtime': 61.1958, 'eval_samples_per_second': 32.012, 'eval_steps_per_second': 4.004, 'epoch': 0.02}
{'loss': 1.9033, 'grad_norm': 32.25, 'learning_rate': 1.665263157894737e-05, 'epoch': 0.02}
{'loss': 2.0597, 'grad_norm': 25.0, 'learning_rate': 1.6442105263157897e-05, 'epoch': 0.02}
{'loss': 2.0137, 'grad_norm': 31.75, 'learning_rate': 1.6231578947368423e-05, 'epoch': 0.02}
{'loss': 1.7893, 'grad_norm': 25.25, 'learning_rate': 1.6021052631578947e-05, 'epoch': 0.02}
{'loss': 1.7787, 'grad_norm': 38.0, 'learning_rate': 1.5810526315789473e-05, 'epoch': 0.02}
{'loss': 1.8563, 'grad_norm': 35.5, 'learning_rate': 1.5600000000000003e-05, 'epoch': 0.02}
{'loss': 1.9934, 'grad_norm': 26.875, 'learning_rate': 1.5389473684210526e-05, 'epoch': 0.02}
{'loss': 2.0868, 'grad_norm': 68.0, 'learning_rate': 1.5178947368421053e-05, 'epoch': 0.02}
{'loss': 1.8462, 'grad_norm': 21.125, 'learning_rate': 1.4968421052631581e-05, 'epoch': 0.02}
{'loss': 1.8873, 'grad_norm': 35.75, 'learning_rate': 1.4757894736842106e-05, 'epoch': 0.02}
{'eval_loss': 0.9240128397941589, 'eval_runtime': 61.2269, 'eval_samples_per_second': 31.996, 'eval_steps_per_second': 4.002, 'epoch': 0.02}
{'loss': 2.0549, 'grad_norm': 20.0, 'learning_rate': 1.4547368421052632e-05, 'epoch': 0.03}
{'loss': 1.7624, 'grad_norm': 21.0, 'learning_rate': 1.433684210526316e-05, 'epoch': 0.03}
{'loss': 1.9213, 'grad_norm': 20.0, 'learning_rate': 1.4126315789473686e-05, 'epoch': 0.03}
{'loss': 2.0409, 'grad_norm': 22.5, 'learning_rate': 1.3915789473684212e-05, 'epoch': 0.03}
{'loss': 1.7024, 'grad_norm': 24.25, 'learning_rate': 1.3705263157894737e-05, 'epoch': 0.03}
{'loss': 1.8671, 'grad_norm': 21.75, 'learning_rate': 1.3494736842105265e-05, 'epoch': 0.03}
{'loss': 1.8034, 'grad_norm': 39.25, 'learning_rate': 1.328421052631579e-05, 'epoch': 0.03}
{'loss': 1.8806, 'grad_norm': 24.25, 'learning_rate': 1.3073684210526317e-05, 'epoch': 0.03}
{'loss': 1.9941, 'grad_norm': 28.75, 'learning_rate': 1.2863157894736845e-05, 'epoch': 0.03}
{'loss': 1.9736, 'grad_norm': 41.75, 'learning_rate': 1.265263157894737e-05, 'epoch': 0.03}
{'eval_loss': 0.9248618483543396, 'eval_runtime': 61.2209, 'eval_samples_per_second': 31.999, 'eval_steps_per_second': 4.002, 'epoch': 0.03}
{'loss': 1.7377, 'grad_norm': 20.125, 'learning_rate': 1.2442105263157895e-05, 'epoch': 0.03}
{'loss': 1.8195, 'grad_norm': 60.5, 'learning_rate': 1.2231578947368421e-05, 'epoch': 0.03}
{'loss': 1.8663, 'grad_norm': 24.75, 'learning_rate': 1.202105263157895e-05, 'epoch': 0.04}
{'loss': 1.9622, 'grad_norm': 28.5, 'learning_rate': 1.1810526315789474e-05, 'epoch': 0.04}
{'loss': 1.993, 'grad_norm': 17.25, 'learning_rate': 1.16e-05, 'epoch': 0.04}
{'loss': 1.9237, 'grad_norm': 37.5, 'learning_rate': 1.1389473684210527e-05, 'epoch': 0.04}
{'loss': 2.0004, 'grad_norm': 62.5, 'learning_rate': 1.1178947368421054e-05, 'epoch': 0.04}
{'loss': 1.9764, 'grad_norm': 74.5, 'learning_rate': 1.0968421052631579e-05, 'epoch': 0.04}
{'loss': 1.8489, 'grad_norm': 18.0, 'learning_rate': 1.0757894736842107e-05, 'epoch': 0.04}
{'loss': 1.7051, 'grad_norm': 25.25, 'learning_rate': 1.0547368421052633e-05, 'epoch': 0.04}
{'eval_loss': 0.923383891582489, 'eval_runtime': 61.1799, 'eval_samples_per_second': 32.02, 'eval_steps_per_second': 4.005, 'epoch': 0.04}
{'loss': 2.119, 'grad_norm': 16.75, 'learning_rate': 1.0336842105263158e-05, 'epoch': 0.04}
{'loss': 2.1083, 'grad_norm': 30.125, 'learning_rate': 1.0126315789473685e-05, 'epoch': 0.04}
{'loss': 1.9209, 'grad_norm': 30.75, 'learning_rate': 9.915789473684211e-06, 'epoch': 0.04}
{'loss': 1.8022, 'grad_norm': 19.25, 'learning_rate': 9.705263157894738e-06, 'epoch': 0.04}
{'loss': 1.7964, 'grad_norm': 22.0, 'learning_rate': 9.494736842105265e-06, 'epoch': 0.05}
{'loss': 1.8393, 'grad_norm': 36.25, 'learning_rate': 9.28421052631579e-06, 'epoch': 0.05}
{'loss': 1.7766, 'grad_norm': 36.5, 'learning_rate': 9.073684210526316e-06, 'epoch': 0.05}
{'loss': 1.7595, 'grad_norm': 22.375, 'learning_rate': 8.863157894736842e-06, 'epoch': 0.05}
{'loss': 1.8925, 'grad_norm': 15.75, 'learning_rate': 8.652631578947369e-06, 'epoch': 0.05}
{'loss': 1.9209, 'grad_norm': 29.125, 'learning_rate': 8.442105263157896e-06, 'epoch': 0.05}
                                                 
{'eval_loss': 0.922676146030426, 'eval_runtime': 61.1916, 'eval_samples_per_second': 32.014, 'eval_steps_per_second': 4.004, 'epoch': 0.05}
{'loss': 1.4429, 'grad_norm': 18.375, 'learning_rate': 8.231578947368422e-06, 'epoch': 0.05}
{'loss': 1.9393, 'grad_norm': 28.25, 'learning_rate': 8.021052631578949e-06, 'epoch': 0.05}
{'loss': 1.8713, 'grad_norm': 33.5, 'learning_rate': 7.810526315789474e-06, 'epoch': 0.05}
{'loss': 1.7878, 'grad_norm': 22.625, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.05}
{'loss': 1.8363, 'grad_norm': 31.125, 'learning_rate': 7.3894736842105275e-06, 'epoch': 0.05}
{'loss': 1.665, 'grad_norm': 21.0, 'learning_rate': 7.178947368421053e-06, 'epoch': 0.05}
{'loss': 1.8027, 'grad_norm': 22.375, 'learning_rate': 6.96842105263158e-06, 'epoch': 0.06}
{'loss': 1.7641, 'grad_norm': 27.125, 'learning_rate': 6.7578947368421054e-06, 'epoch': 0.06}
{'loss': 1.889, 'grad_norm': 25.75, 'learning_rate': 6.547368421052632e-06, 'epoch': 0.06}
{'loss': 1.8527, 'grad_norm': 20.375, 'learning_rate': 6.336842105263158e-06, 'epoch': 0.06}
{'eval_loss': 0.9223125576972961, 'eval_runtime': 61.1845, 'eval_samples_per_second': 32.018, 'eval_steps_per_second': 4.004, 'epoch': 0.06}
{'loss': 2.0427, 'grad_norm': 18.5, 'learning_rate': 6.126315789473685e-06, 'epoch': 0.06}
{'loss': 1.8715, 'grad_norm': 22.0, 'learning_rate': 5.915789473684212e-06, 'epoch': 0.06}
{'loss': 1.9457, 'grad_norm': 27.5, 'learning_rate': 5.705263157894737e-06, 'epoch': 0.06}
{'loss': 2.2807, 'grad_norm': 28.625, 'learning_rate': 5.494736842105264e-06, 'epoch': 0.06}
{'loss': 1.523, 'grad_norm': 20.0, 'learning_rate': 5.2842105263157896e-06, 'epoch': 0.06}
{'loss': 1.7016, 'grad_norm': 48.75, 'learning_rate': 5.073684210526316e-06, 'epoch': 0.06}
{'loss': 1.9161, 'grad_norm': 19.125, 'learning_rate': 4.863157894736843e-06, 'epoch': 0.06}
{'loss': 2.0789, 'grad_norm': 31.625, 'learning_rate': 4.652631578947368e-06, 'epoch': 0.06}
{'loss': 1.6401, 'grad_norm': 15.1875, 'learning_rate': 4.442105263157896e-06, 'epoch': 0.07}
{'loss': 2.0627, 'grad_norm': 20.25, 'learning_rate': 4.2315789473684215e-06, 'epoch': 0.07}
{'eval_loss': 0.922004759311676, 'eval_runtime': 61.1701, 'eval_samples_per_second': 32.025, 'eval_steps_per_second': 4.005, 'epoch': 0.07}
{'loss': 1.8264, 'grad_norm': 37.0, 'learning_rate': 4.021052631578948e-06, 'epoch': 0.07}
{'loss': 1.7388, 'grad_norm': 19.625, 'learning_rate': 3.810526315789474e-06, 'epoch': 0.07}
{'loss': 1.8592, 'grad_norm': 22.25, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.07}
{'loss': 1.8628, 'grad_norm': 23.75, 'learning_rate': 3.3894736842105264e-06, 'epoch': 0.07}
{'loss': 1.6945, 'grad_norm': 19.5, 'learning_rate': 3.178947368421053e-06, 'epoch': 0.07}
{'loss': 1.8725, 'grad_norm': 28.0, 'learning_rate': 2.9684210526315795e-06, 'epoch': 0.07}
{'loss': 1.9676, 'grad_norm': 28.875, 'learning_rate': 2.7578947368421056e-06, 'epoch': 0.07}
{'loss': 1.7893, 'grad_norm': 63.0, 'learning_rate': 2.5473684210526317e-06, 'epoch': 0.07}
{'loss': 1.7867, 'grad_norm': 34.5, 'learning_rate': 2.3368421052631583e-06, 'epoch': 0.07}
{'loss': 1.5208, 'grad_norm': 17.375, 'learning_rate': 2.1263157894736844e-06, 'epoch': 0.07}
{'eval_loss': 0.9220147132873535, 'eval_runtime': 61.1532, 'eval_samples_per_second': 32.034, 'eval_steps_per_second': 4.006, 'epoch': 0.07}
{'loss': 1.7618, 'grad_norm': 47.5, 'learning_rate': 1.9157894736842105e-06, 'epoch': 0.08}
{'loss': 1.9771, 'grad_norm': 52.0, 'learning_rate': 1.705263157894737e-06, 'epoch': 0.08}
{'loss': 1.8694, 'grad_norm': 17.125, 'learning_rate': 1.4947368421052632e-06, 'epoch': 0.08}
{'loss': 1.7404, 'grad_norm': 21.375, 'learning_rate': 1.2842105263157895e-06, 'epoch': 0.08}
{'loss': 1.7392, 'grad_norm': 28.375, 'learning_rate': 1.0736842105263159e-06, 'epoch': 0.08}
{'loss': 1.9486, 'grad_norm': 28.25, 'learning_rate': 8.631578947368421e-07, 'epoch': 0.08}
{'loss': 1.7732, 'grad_norm': 13.75, 'learning_rate': 6.526315789473684e-07, 'epoch': 0.08}
{'loss': 1.8733, 'grad_norm': 25.875, 'learning_rate': 4.421052631578947e-07, 'epoch': 0.08}
{'loss': 1.9304, 'grad_norm': 21.5, 'learning_rate': 2.315789473684211e-07, 'epoch': 0.08}
{'loss': 1.7765, 'grad_norm': 21.25, 'learning_rate': 2.1052631578947368e-08, 'epoch': 0.08}
{'eval_loss': 0.9219980239868164, 'eval_runtime': 61.1804, 'eval_samples_per_second': 32.02, 'eval_steps_per_second': 4.005, 'epoch': 0.08}
100%|██████████| 1000/1000 [1:02:39<00:00,  3.08s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'train_runtime': 3759.4994, 'train_samples_per_second': 4.256, 'train_steps_per_second': 0.266, 'train_loss': 1.8803317728042603, 'epoch': 0.08}
100%|██████████| 1000/1000 [1:03:14<00:00,  3.79s/it]
100%|██████████| 245/245 [01:01<00:00,  4.01it/s]
wandb: WARNING Tried to log to step 1000 that is less than the current step 1002. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Round 0 student evaluation: {'eval_loss': 0.9476798663333971}
Traceback (most recent call last):
  File "/h/klambert/slm_ensembles/train.py", line 338, in <module>
    "student_bleu": student_eval_results["bleu"],
KeyError: 'bleu'
